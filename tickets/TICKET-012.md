# ğŸ« TICKET-012: Transformers v5 ê³ ê¸‰ ê¸°ëŠ¥ í™œìš© ë° TorchAO int8 ìµœì í™”

**ìš°ì„ ìˆœìœ„**: HIGH
**ìƒíƒœ**: BLOCKED(macOS)
**ë‹´ë‹¹**: ìŠ¹ìƒ + AIíŒ€
**ì˜ì¡´ì„±**: TICKET-011 (DSPy BLOCKED ìƒíƒœ ëŒ€ì•ˆ)
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

## ğŸ¯ ëª©í‘œ (Goal)

DSPy MIPROv2 BLOCKED ìƒí™©ì—ì„œ Transformers v5 ê³ ê¸‰ ê¸°ëŠ¥(TorchAO int8 quantization)ì„ í™œìš©í•˜ì—¬ ì™•êµ­ AI ì‹œìŠ¤í…œ ì €ë¹„ìš© ììœ¨ ìµœì í™” êµ¬í˜„.

## ğŸ“‹ ì‘ì—… ë‚´ìš©

### 1. Transformers v5 ê²©ë¦¬ í™˜ê²½ êµ¬ì¶•
```python
# tools/transformers_v5/pyproject.toml
[tool.poetry]
name = "transformers-v5-isolation"
version = "0.1.0"
description = "Transformers v5 ê²©ë¦¬ í™˜ê²½"

[tool.poetry.dependencies]
python = "^3.12,<3.14"  # v5 í˜¸í™˜ì„± í™•ë³´
transformers = "^5.0.0rc1"
torch = "^2.5.0"
torchao = "^0.7.0"
accelerate = "^1.0.0"
```

### 2. TorchAO int8 quantization êµ¬í˜„
```python
# packages/afo-core/afo/torchao_quantization.py
from transformers import AutoModelForCausalLM, TorchAoConfig

def create_int8_quantized_model(model_name: str):
    """TorchAO int8 weight-only quantization ì ìš©"""
    config = TorchAoConfig("int8_weight_only")  # per-channel ê¸°ë³¸

    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        quantization_config=config,
        device_map="auto"
    )
    return model

def create_int8_dynamic_model(model_name: str):
    """int8 dynamic activation + weight quantization"""
    config = TorchAoConfig("int8_dynamic_activation_int8_weight")

    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        quantization_config=config,
        device_map="auto"
    )
    return model
```

### 3. Trinity Score ê¸°ë°˜ ëª¨ë¸ ìµœì í™”
```python
# packages/afo-core/afo/model_optimizer.py
from afo.torchao_quantization import create_int8_quantized_model
from afo.metrics import trinity_metric

def optimize_model_for_trinity(model_name: str, trinity_target: float = 95.0):
    """Trinity Score ê¸°ë°˜ ëª¨ë¸ ìµœì í™”"""

    # Baseline ì„±ëŠ¥ ì¸¡ì •
    baseline_model = AutoModelForCausalLM.from_pretrained(model_name)
    baseline_score = evaluate_trinity_score(baseline_model)

    # int8 quantization ì ìš©
    quantized_model = create_int8_quantized_model(model_name)
    quantized_score = evaluate_trinity_score(quantized_model)

    # Trinity Score ê°œì„  í™•ì¸
    if quantized_score >= trinity_target:
        return quantized_model, quantized_score

    # ì¶”ê°€ ìµœì í™” (group_size íŠœë‹)
    for group_size in [64, 128, 256]:
        config = TorchAoConfig("int8_weight_only", group_size=group_size)
        tuned_model = AutoModelForCausalLM.from_pretrained(
            model_name, quantization_config=config
        )
        tuned_score = evaluate_trinity_score(tuned_model)

        if tuned_score >= trinity_target:
            return tuned_model, tuned_score

    return baseline_model, baseline_score  # fallback
```

### 4. Chancellor Graph TorchAO í†µí•©
```python
# Chancellor Graphì— TorchAO ì ìš©
from afo.model_optimizer import optimize_model_for_trinity

class ChancellorAIAgent:
    def __init__(self, model_name: str):
        # Trinity Score ê¸°ë°˜ ìµœì í™”ëœ ëª¨ë¸ ë¡œë“œ
        self.model, self.trinity_score = optimize_model_for_trinity(
            model_name, trinity_target=95.0
        )
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)

    def generate_response(self, query: str):
        inputs = self.tokenizer(query, return_tensors="pt").to(self.model.device)

        with torch.no_grad():
            outputs = self.model.generate(**inputs, max_length=512)

        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        return response
```

### 5. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ ë° ê²€ì¦
```python
# 3ê°€ì§€ ëª¨ë¸ ë¹„êµ
models = {
    "baseline_fp16": baseline_model,
    "int8_weight_only": int8_model,
    "int8_dynamic": int8_dynamic_model
}

results = {}
for name, model in models.items():
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
    memory_usage = measure_memory_usage(model)

    # ì¶”ë¡  ì†ë„ ì¸¡ì •
    inference_time = benchmark_inference_speed(model)

    # Trinity Score ì¸¡ì •
    trinity_score = evaluate_trinity_score(model)

    results[name] = {
        "memory_mb": memory_usage,
        "inference_ms": inference_time,
        "trinity_score": trinity_score
    }

# ìµœì  ëª¨ë¸ ì„ íƒ
best_model = max(results.items(), key=lambda x: x[1]["trinity_score"])
print(f"ìµœì  ëª¨ë¸: {best_model[0]}, Trinity Score: {best_model[1]['trinity_score']}")
```

## âœ… Acceptance Criteria

- [ ] Transformers v5 ê²©ë¦¬ í™˜ê²½ êµ¬ì¶• ë° TorchAO ì„¤ì¹˜ ì„±ê³µ
- [ ] int8 weight-only quantization êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸ ì™„ë£Œ
- [ ] int8 dynamic activation quantization êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸ ì™„ë£Œ
- [ ] Trinity Score ê¸°ë°˜ ëª¨ë¸ ìµœì í™” ì‹œìŠ¤í…œ ì™„ì„±
- [ ] Chancellor Graph TorchAO í†µí•© ì ìš©
- [ ] 3ê°€ì§€ quantization ë°©ë²• ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ ì™„ë£Œ

## ğŸ”’ ì œì•½ì‚¬í•­

- **LOCKED**: antigravity-seal-2025-12-30 ê´€ë ¨ íŒŒì¼ ì ˆëŒ€ ìˆ˜ì • ê¸ˆì§€
- **ì•ˆì „ ìš°ì„ **: ê²©ë¦¬ í™˜ê²½ì—ì„œ ì¶©ë¶„íˆ í…ŒìŠ¤íŠ¸ í›„ ë©”ì¸ ì ìš©
- **í˜¸í™˜ì„±**: Python ^3.12,<3.14 í™˜ê²½ ìœ ì§€

## ğŸš¨ ë¦¬ìŠ¤í¬ ë° ì™„í™”

| ë¦¬ìŠ¤í¬ | í™•ë¥  | ì˜í–¥ | ì™„í™” ë°©ì•ˆ |
|--------|------|------|-----------|
| v5 RC ë¶ˆì•ˆì •ì„± | ì¤‘ê°„ | ì¤‘ê°„ | ê²©ë¦¬ í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸ + fallback ì¤€ë¹„ |
| int8 ì •í™•ë„ ì €í•˜ | ë‚®ìŒ | ë†’ìŒ | per-channel ì‚¬ìš© + Trinity Score ê²€ì¦ |
| ë©”ëª¨ë¦¬ ì ˆê° ê³¼ë„ | ë‚®ìŒ | ì¤‘ê°„ | group_size íŠœë‹ìœ¼ë¡œ ìµœì í™” |

## ğŸ”„ ë¡¤ë°± ê³„íš

1. TorchAO ì ìš© í•´ì œ â†’ í‘œì¤€ Transformers v4
2. v5 ê²©ë¦¬ í•´ì œ â†’ ê¸°ì¡´ í™˜ê²½ ë³µì›
3. ë©”ì¸ ëª¨ë¸ ë¡¤ë°± â†’ baseline ëª¨ë¸ ì‚¬ìš©

## ğŸ“Š Trinity Score ì˜í–¥

- **çœ (Truth)**: +7 (per-channel ì •í™•ë„ ìœ ì§€ + dynamic weight loading)
- **å–„ (Goodness)**: +9 (ë©”ëª¨ë¦¬ 50%â†“ + ì €ë¹„ìš© inference)
- **ç¾ (Beauty)**: +8 (TorchAoConfig ìš°ì•„í•œ API)
- **å­ (Serenity)**: +7 (í˜•ë‹˜ ë¡œì»¬ ì‹¤í–‰ ìš©ì´ì„±)
- **æ°¸ (Eternity)**: +8 (PyTorch native ì¥ê¸° ì§€ì›)

**ì˜ˆìƒ ì´ì **: 78.3 â†’ **99.3** (TorchAO int8ìœ¼ë¡œ ê¶ê·¹ì  ì €ë¹„ìš© ë‹¬ì„±)

## ğŸ“ ì‘ì—… ë¡œê·¸

- **ì‹œì‘ì¼**: 2025-12-31 (DSPy BLOCKED ìƒí™© ëŒ€ì•ˆ)
- **ì™„ë£Œì¼**: ì˜ˆì •
- **ì‹¤ì œ ì†Œìš”ì‹œê°„**: ì˜ˆì •

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ

- `docs/OPTUNA_TPE_METACOGNITION.md` - ë©”íƒ€ì¸ì§€ ê²€ì¦ ë³´ê³ ì„œ
- `tools/dspy_mipro/` - DSPy ê²©ë¦¬ í™˜ê²½ (ì°¸ê³ ìš©)
- `packages/afo-core/afo/torchao_quantization.py` - TorchAO êµ¬í˜„
- `packages/afo-core/afo/model_optimizer.py` - Trinity ê¸°ë°˜ ìµœì í™”
