#!/usr/bin/env python3
"""
GoT (Graph of Thought) Example Implementation for AFO Kingdom Chancellor V2

This module demonstrates Graph of Thought implementation using LangGraph,
integrated with AFO Kingdom's Chancellor Graph V2 architecture.

Features:
- Node-based thought generation and evaluation
- Redis checkpointing for state persistence
- Conditional edges for branching logic
- Trinity Score integration for decision making
- Context7 knowledge injection

Author: AFO Kingdom Chancellor System
Date: 2026-01-01
"""

import json
import os
import time
from datetime import datetime
from typing import Annotated

import redis
from langchain_core.messages import AIMessage, HumanMessage
from langgraph.graph import END, START, StateGraph
from langgraph.graph.message import add_messages
from typing_extensions import TypedDict as TypedDictExt

# Redis configuration
REDIS_HOST = os.getenv("REDIS_HOST", "localhost")
REDIS_PORT = int(os.getenv("REDIS_PORT", 6379))
REDIS_DB = int(os.getenv("REDIS_DB", 0))

# Initialize Redis client
redis_client = redis.Redis(host=REDIS_HOST, port=REDIS_PORT, db=REDIS_DB, decode_responses=True)


class GoTState(TypedDictExt):
    """Graph of Thought state definition"""

    messages: Annotated[list, add_messages]  # Thought chain messages
    thoughts: list[str]  # GoT vertices (thought units)
    best_thought: str  # Final aggregated thought
    checkpoint: str  # Redis checkpoint key
    trinity_score: dict  # Trinity Score for decision making
    context7_data: dict  # Context7 injected knowledge


def generate_thoughts(state: GoTState) -> dict:
    """
    Generate thoughts node (aggregation â†’ generation)

    This represents the initial thought generation phase in GoT,
    where multiple ideas are generated from the input.
    """
    input_message = state["messages"][-1].content
    prompt = f"AFO ì™•êµ­ ì² í•™ ê¸°ë°˜ìœ¼ë¡œ '{input_message}' ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ 3ê°€ì§€ ì•„ì´ë””ì–´ ìƒì„±"

    # Simulate LLM call with Trinity Score consideration
    base_ideas = [
        "çœ: ê¸°ìˆ ì  ì •í™•ì„± ê¸°ë°˜ í•´ê²° ë°©ì•ˆ",
        "å–„: ìœ¤ë¦¬ì  ì•ˆì •ì„± ìš°ì„  í•´ê²° ë°©ì•ˆ",
        "ç¾: ìš°ì•„í•œ êµ¬ì¡°ì  í•´ê²° ë°©ì•ˆ",
    ]

    # Enhance with Context7 knowledge if available
    if state.get("context7_data"):
        context_knowledge = state["context7_data"].get("technical_patterns", [])
        if context_knowledge:
            base_ideas.extend([f"Context7 ê¸°ë°˜: {k}" for k in context_knowledge[:2]])

    # Create checkpoint
    checkpoint_key = f"got_generate_{int(time.time())}"
    checkpoint_data = {
        "timestamp": datetime.now().isoformat(),
        "input": input_message,
        "generated_thoughts": base_ideas,
        "trinity_score": state.get("trinity_score", {}),
    }

    redis_client.set(checkpoint_key, json.dumps(checkpoint_data))

    return {"thoughts": state["thoughts"] + base_ideas, "checkpoint": checkpoint_key}


def evaluate_thoughts(state: GoTState) -> dict:
    """
    Evaluate thoughts node (scoring and selection)

    This represents the evaluation phase where thoughts are scored
    and the best one is selected based on Trinity Score criteria.
    """
    thoughts = state["thoughts"]
    trinity_weights = {
        "truth": 0.35,
        "goodness": 0.35,
        "beauty": 0.20,
        "serenity": 0.08,
        "eternity": 0.02,
    }

    # Simulate scoring based on Trinity Score
    scores = []
    for thought in thoughts:
        # Simple scoring based on keywords (çœå–„ç¾ keywords)
        score = 0.5  # Base score
        if "çœ" in thought or "ê¸°ìˆ " in thought:
            score += 0.2
        if "å–„" in thought or "ì•ˆì •" in thought:
            score += 0.2
        if "ç¾" in thought or "ìš°ì•„" in thought:
            score += 0.15
        scores.append(min(score, 1.0))  # Cap at 1.0

    # Select best thought
    best_idx = scores.index(max(scores))
    best_thought = thoughts[best_idx]

    # Create checkpoint
    checkpoint_key = f"got_evaluate_{int(time.time())}"
    checkpoint_data = {
        "timestamp": datetime.now().isoformat(),
        "thoughts": thoughts,
        "scores": scores,
        "best_thought": best_thought,
        "trinity_score": state.get("trinity_score", {}),
    }

    redis_client.set(checkpoint_key, json.dumps(checkpoint_data))

    return {
        "best_thought": best_thought,
        "messages": state["messages"]
        + [AIMessage(content=f"ìµœê³  ì•„ì´ë””ì–´ ì„ íƒ: {best_thought} (ì ìˆ˜: {max(scores):.2f})")],
        "checkpoint": checkpoint_key,
    }


def improve_thought(state: GoTState) -> dict:
    """
    Improve thought node (feedback loop and enhancement)

    This represents the improvement phase where the selected thought
    is enhanced with additional context and Trinity Score optimization.
    """
    best_thought = state["best_thought"]

    # Enhance with AFO Kingdom philosophy
    enhanced_thought = f"{best_thought} + çœå–„ç¾å­æ°¸ ì² í•™ í†µí•© ìµœì í™”"

    # Add Context7 insights if available
    if state.get("context7_data"):
        insights = state["context7_data"].get("insights", [])
        if insights:
            enhanced_thought += f" + Context7 ì¸ì‚¬ì´íŠ¸: {insights[0]}"

    # Create checkpoint
    checkpoint_key = f"got_improve_{int(time.time())}"
    checkpoint_data = {
        "timestamp": datetime.now().isoformat(),
        "original_thought": best_thought,
        "enhanced_thought": enhanced_thought,
        "trinity_score": state.get("trinity_score", {}),
    }

    redis_client.set(checkpoint_key, json.dumps(checkpoint_data))

    return {
        "thoughts": [enhanced_thought],
        "messages": state["messages"]
        + [AIMessage(content=f"ê°œì„ ëœ í•´ê²° ë°©ì•ˆ: {enhanced_thought}")],
        "checkpoint": checkpoint_key,
    }


def create_got_graph() -> StateGraph:
    """
    Create the Graph of Thought workflow

    This implements the core GoT structure with nodes and conditional edges,
    following AFO Kingdom Chancellor Graph V2 patterns.
    """
    # Initialize workflow
    workflow = StateGraph(GoTState)

    # Add nodes (GoT operations)
    workflow.add_node("generate", generate_thoughts)
    workflow.add_node("evaluate", evaluate_thoughts)
    workflow.add_node("improve", improve_thought)

    # Define edges (GoT flow)
    workflow.add_edge(START, "generate")
    workflow.add_edge("generate", "evaluate")

    # Conditional edge: improve if we have fewer than optimal thoughts
    workflow.add_conditional_edges(
        "evaluate",
        lambda state: "improve" if len(state["thoughts"]) < 5 else END,
        {"improve": "improve", END: END},
    )

    # Feedback loop for iterative improvement
    workflow.add_edge("improve", "generate")

    return workflow


def run_got_example(problem: str = "2026ë…„ AFO ì™•êµ­ AI ì‹œìŠ¤í…œ ìµœì í™” ë°©ì•ˆ") -> dict:
    """
    Execute Graph of Thought example

    Args:
        problem: The problem to solve using GoT

    Returns:
        Final result with thoughts and checkpoints
    """
    print("ğŸ° AFO ì™•êµ­ GoT (Graph of Thought) ì‹¤í–‰ ì‹œì‘")
    print(f"ë¬¸ì œ: {problem}")
    print("-" * 50)

    # Test Redis connection
    try:
        redis_client.ping()
        print("âœ… Redis ì—°ê²° ì„±ê³µ")
    except redis.ConnectionError:
        print("âŒ Redis ì—°ê²° ì‹¤íŒ¨ - Redis ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”")
        return {"error": "Redis connection failed"}

    # Create workflow
    workflow = create_got_graph()
    graph = workflow.compile()

    # Initial state
    initial_state = {
        "messages": [HumanMessage(content=problem)],
        "thoughts": [],
        "best_thought": "",
        "checkpoint": f"got_start_{int(time.time())}",
        "trinity_score": {
            "truth": 0.9,
            "goodness": 0.85,
            "beauty": 0.8,
            "serenity": 0.95,
            "eternity": 0.9,
        },
        "context7_data": {
            "technical_patterns": ["ë³‘ë ¬ ì²˜ë¦¬", "ìºì‹± ìµœì í™”"],
            "insights": ["íŠ¸ë¦¬ë‹ˆí‹° ìŠ¤ì½”ì–´ ê¸°ë°˜ ì˜ì‚¬ê²°ì •"],
        },
    }

    # Execute
    print("ğŸš€ GoT ê·¸ë˜í”„ ì‹¤í–‰ ì¤‘...")
    result = graph.invoke(initial_state)

    print("âœ… GoT ì‹¤í–‰ ì™„ë£Œ")
    print(f"ìµœì¢… ê²°ê³¼: {result['best_thought']}")
    print(f"ìƒì„±ëœ ìƒê° ìˆ˜: {len(result['thoughts'])}")
    print(f"ìµœì¢… ì²´í¬í¬ì¸íŠ¸: {result['checkpoint']}")

    # Show checkpoints
    print("\nğŸ“‹ Redis ì²´í¬í¬ì¸íŠ¸ í™•ì¸:")
    for key in redis_client.keys("got_*"):
        if "start" not in key:  # Skip start checkpoint
            data = json.loads(redis_client.get(key))
            print(f"  {key}: {data.get('timestamp', 'N/A')}")

    return result


if __name__ == "__main__":
    # Execute example
    result = run_got_example()

    if "error" not in result:
        print("\nğŸ¯ GoT ì‹¤í–‰ ì„±ê³µ! AFO ì™•êµ­ Chancellor Graph V2 ê¸°ë°˜ Graph of Thought êµ¬í˜„ í™•ì¸")
        print(f"Trinity Score: {result.get('trinity_score', {})}")
    else:
        print(f"\nâŒ ì‹¤í–‰ ì‹¤íŒ¨: {result['error']}")
