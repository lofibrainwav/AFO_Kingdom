#!/usr/bin/env python3
"""
MIPROv2 í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ - ê°„ë‹¨í•œ ì§ˆë¬¸-ë‹µë³€ í”„ë¡œê·¸ë¨ ìµœì í™”

TICKET-001: MIPROv2 ê²©ë¦¬ venv í…ŒìŠ¤íŠ¸
DSPy MIPROv2ë¥¼ ì‚¬ìš©í•œ ê°„ë‹¨í•œ Q&A í”„ë¡œê·¸ë¨ ìµœì í™” ì˜ˆì‹œ
"""

import dspy
from dspy.teleprompt import BootstrapFewShot

# MIPROv2 ì˜µí‹°ë§ˆì´ì € ì„í¬íŠ¸
from afo.dspy.mipro_v2_optimizer import MIPROv2Optimizer, TrinityAwareMIPROv2


class SimpleQA(dspy.Module):
    """ê°„ë‹¨í•œ ì§ˆë¬¸-ë‹µë³€ DSPy ëª¨ë“ˆ"""

    def __init__(self):
        super().__init__()
        self.generate_answer = dspy.ChainOfThought("question -> answer")

    def forward(self, question: str) -> str:
        """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±"""
        result = self.generate_answer(question=question)
        return result.answer


def create_sample_dataset():
    """ìƒ˜í”Œ ë°ì´í„°ì…‹ ìƒì„±"""
    trainset = [
        dspy.Example(question="What is the capital of France?", answer="Paris").with_inputs(
            "question"
        ),
        dspy.Example(question="What is 2 + 2?", answer="4").with_inputs("question"),
        dspy.Example(question="What color is the sky on a clear day?", answer="Blue").with_inputs(
            "question"
        ),
        dspy.Example(
            question="What is the largest planet in our solar system?", answer="Jupiter"
        ).with_inputs("question"),
        dspy.Example(question="What do bees produce?", answer="Honey").with_inputs("question"),
    ]
    return trainset


def basic_accuracy_metric(prediction: str, gold: str) -> bool:
    """ê¸°ë³¸ ì •í™•ë„ ë©”íŠ¸ë¦­"""
    return prediction.strip().lower() == gold.strip().lower()


async def test_basic_dspy():
    """ê¸°ë³¸ DSPy ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” Testing basic DSPy functionality...")

    # LM ì„¤ì • - AFO ì™•êµ­ ìì²´ ì œì‘ Ollama ì‹œìŠ¤í…œ ìš°ì„  ì‚¬ìš©
    try:
        # DSPyì˜ Ollama ì§€ì› í™•ì¸ ë° ì‚¬ìš©
        import requests

        # Ollama ì§ì ‘ API ì‚¬ìš© (DSPy wrapperê°€ ì—†ì„ ê²½ìš°)
        class OllamaLM:
            def __init__(self, model="llama3.2:3b", port=11435, timeout_s=120):
                self.model = model
                self.base_url = f"http://localhost:{port}"
                self.timeout = timeout_s

            def __call__(self, prompt, **kwargs):
                try:
                    response = requests.post(
                        f"{self.base_url}/api/generate",
                        json={"model": self.model, "prompt": prompt, "stream": False},
                        timeout=self.timeout,
                    )
                    if response.status_code == 200:
                        result = response.json()
                        return result.get("response", "")
                    else:
                        raise Exception(f"Ollama API error: {response.status_code}")
                except Exception as e:
                    raise Exception(f"Ollama call failed: {e}")

            def __str__(self):
                return f"OllamaLM({self.model})"

        lm = OllamaLM(model="llama3.2:3b", port=11435, timeout_s=120)
        dspy.settings.configure(lm=lm)
        print("âœ… DSPy configured with AFO Kingdom Ollama system")

    except Exception as e:
        print(f"âš ï¸  Ollama not available ({e}), falling back to mock LM")

        # Fallback: ëª¨ì˜ LM (API í˜¸ì¶œ ì—†ì´)
        class MockLM:
            def __call__(self, prompt, **kwargs):
                return f"Mock response for: {prompt[:50]}..."

            def __str__(self):
                return "MockLM (AFO Kingdom fallback)"

        lm = MockLM()
        dspy.settings.configure(lm=lm)

    # í”„ë¡œê·¸ë¨ ìƒì„± ë° í…ŒìŠ¤íŠ¸
    program = SimpleQA()
    question = "What is the capital of France?"
    result = program(question=question)

    print(f"Question: {question}")
    print(f"Answer: {result}")
    print("âœ… Basic DSPy test passed!")


async def test_bootstrap_fewshot():
    """BootstrapFewShotìœ¼ë¡œ ê¸°ë³¸ ìµœì í™” í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Testing BootstrapFewShot optimization...")

    # LM ì„¤ì • - AFO ì™•êµ­ Ollama ì‹œìŠ¤í…œ ìš°ì„  ì‚¬ìš©
    try:
        import requests

        class OllamaLM:
            def __init__(self, model="llama3.2:3b", port=11435, timeout_s=120):
                self.model = model
                self.base_url = f"http://localhost:{port}"
                self.timeout = timeout_s

            def __call__(self, prompt, **kwargs):
                try:
                    response = requests.post(
                        f"{self.base_url}/api/generate",
                        json={"model": self.model, "prompt": prompt, "stream": False},
                        timeout=self.timeout,
                    )
                    if response.status_code == 200:
                        result = response.json()
                        return result.get("response", "")
                    else:
                        raise Exception(f"Ollama API error: {response.status_code}")
                except Exception as e:
                    raise Exception(f"Ollama call failed: {e}")

            def __str__(self):
                return f"OllamaLM({self.model})"

        lm = OllamaLM(model="llama3.2:3b", port=11435, timeout_s=120)
        dspy.settings.configure(lm=lm)
        print("âœ… BootstrapFewShot configured with AFO Kingdom Ollama")
    except Exception as e:
        print(f"âš ï¸  Ollama not available for BootstrapFewShot ({e}), skipping test")
        return

    # ë°ì´í„°ì…‹ ìƒì„±
    trainset = create_sample_dataset()

    # í”„ë¡œê·¸ë¨ ìƒì„±
    program = SimpleQA()

    # BootstrapFewShot ìµœì í™”
    teleprompter = BootstrapFewShot(metric=basic_accuracy_metric, max_bootstrapped_demos=2)
    optimized_program = teleprompter.compile(program, trainset=trainset)

    # í…ŒìŠ¤íŠ¸
    test_question = "What is 2 + 2?"
    result = optimized_program(question=test_question)
    print(f"Test Question: {test_question}")
    print(f"Optimized Answer: {result}")
    print("âœ… BootstrapFewShot test passed!")


async def test_mipro_v2_basic():
    """MIPROv2 ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Testing MIPROv2 basic functionality...")

    # ë°ì´í„°ì…‹ ìƒì„±
    trainset = create_sample_dataset()

    # í”„ë¡œê·¸ë¨ ìƒì„±
    program = SimpleQA()

    # MIPROv2 ì˜µí‹°ë§ˆì´ì € ìƒì„±
    optimizer = MIPROv2Optimizer(
        num_candidates=5,
        init_temperature=1.0,
        verbose=True,
        num_threads=1,  # API ë¹„ìš© ì ˆê°ì„ ìœ„í•´ 1ë¡œ ì„¤ì •
    )

    print("Starting MIPROv2 optimization (this may take a few minutes)...")

    try:
        # ìµœì í™” ì‹¤í–‰ (ê°„ë‹¨í•œ ì„¤ì •ìœ¼ë¡œ í…ŒìŠ¤íŠ¸)
        optimized_program = await optimizer.optimize(
            program=program,
            trainset=trainset,
            num_trials=3,  # ë¹„ìš© ì ˆê°ì„ ìœ„í•´ ì ì€ trial ìˆ˜
            max_bootstrapped_demos=2,
            max_labeled_demos=2,
        )

        print("âœ… MIPROv2 optimization completed!")

        # ìµœì í™” ê²°ê³¼ í…ŒìŠ¤íŠ¸
        test_question = "What is the largest planet?"
        result = optimized_program(question=test_question)
        print(f"Test Question: {test_question}")
        print(f"MIPROv2 Optimized Answer: {result}")

        # ì¦ê±° í™•ì¸
        history = optimizer.get_optimization_history()
        print(f"Optimization steps recorded: {len(history)}")

        return True

    except Exception as e:
        print(f"âŒ MIPROv2 test failed: {e}")
        return False


async def test_trinity_mipro():
    """Trinity ì¸ì‹ MIPROv2 í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Testing Trinity-aware MIPROv2...")

    # ë°ì´í„°ì…‹ ìƒì„±
    trainset = create_sample_dataset()

    # í”„ë¡œê·¸ë¨ ìƒì„±
    program = SimpleQA()

    # Trinity ì¸ì‹ ì˜µí‹°ë§ˆì´ì € ìƒì„±
    trinity_optimizer = TrinityAwareMIPROv2(
        trinity_weights={
            "truth": 0.4,  # ì •í™•ì„± ìš°ì„ 
            "goodness": 0.3,  # ì•ˆì •ì„±
            "beauty": 0.2,  # ë‹¨ìˆœí•¨
            "serenity": 0.05,  # í‰ì˜¨
            "eternity": 0.05,  # ì§€ì†ì„±
        },
        num_candidates=3,
        verbose=True,
        num_threads=1,
    )

    print("Starting Trinity-aware MIPROv2 optimization...")

    try:
        # ìµœì í™” ì‹¤í–‰
        optimized_program = await trinity_optimizer.optimize(
            program=program,
            trainset=trainset,
            num_trials=2,  # ë” ì ì€ trialë¡œ í…ŒìŠ¤íŠ¸
            max_bootstrapped_demos=1,
            max_labeled_demos=1,
        )

        print("âœ… Trinity MIPROv2 optimization completed!")

        # í…ŒìŠ¤íŠ¸
        test_question = "What color is the sky?"
        result = optimized_program(question=test_question)
        print(f"Test Question: {test_question}")
        print(f"Trinity Optimized Answer: {result}")

        # Trinity ê°€ì¤‘ì¹˜ í™•ì¸
        print(f"Trinity weights used: {trinity_optimizer.trinity_weights}")

        return True

    except Exception as e:
        print(f"âŒ Trinity MIPROv2 test failed: {e}")
        return False


async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸš€ AFO Kingdom MIPROv2 Test Suite")
    print("=" * 60)

    # OpenAI API í‚¤ í™•ì¸
    if not dspy.settings.lm or not hasattr(dspy.settings.lm, "api_key"):
        print("âš ï¸  OpenAI API key not configured. Set OPENAI_API_KEY environment variable.")
        print("Running limited tests without API calls...")

        # API í‚¤ ì—†ëŠ” ê¸°ë³¸ í…ŒìŠ¤íŠ¸ë§Œ
        print("\nğŸ” Running API-free tests...")
        optimizer = MIPROv2Optimizer(verbose=True)
        print(f"âœ… MIPROv2Optimizer created: {type(optimizer).__name__}")

        trinity_optimizer = TrinityAwareMIPROv2(verbose=True)
        print(f"âœ… TrinityAwareMIPROv2 created: {type(trinity_optimizer).__name__}")
        print(f"   Trinity weights: {trinity_optimizer.trinity_weights}")

        print("\nğŸ¯ API-free tests completed!")
        return

    # API í‚¤ê°€ ìˆëŠ” ê²½ìš° ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    results = []

    # ê¸°ë³¸ DSPy í…ŒìŠ¤íŠ¸
    try:
        await test_basic_dspy()
        results.append(("Basic DSPy", True))
    except Exception as e:
        print(f"âŒ Basic DSPy test failed: {e}")
        results.append(("Basic DSPy", False))

    # BootstrapFewShot í…ŒìŠ¤íŠ¸
    try:
        await test_bootstrap_fewshot()
        results.append(("BootstrapFewShot", True))
    except Exception as e:
        print(f"âŒ BootstrapFewShot test failed: {e}")
        results.append(("BootstrapFewShot", False))

    # MIPROv2 ê¸°ë³¸ í…ŒìŠ¤íŠ¸
    mipro_result = await test_mipro_v2_basic()
    results.append(("MIPROv2 Basic", mipro_result))

    # Trinity MIPROv2 í…ŒìŠ¤íŠ¸
    trinity_result = await test_trinity_mipro()
    results.append(("Trinity MIPROv2", trinity_result))

    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“Š Test Results Summary:")
    for test_name, success in results:
        status = "âœ… PASS" if success else "âŒ FAIL"
        print(f"  {test_name}: {status}")

    successful_tests = sum(1 for _, success in results if success)
    total_tests = len(results)

    print(f"\nğŸ¯ Overall: {successful_tests}/{total_tests} tests passed")

    if successful_tests == total_tests:
        print("ğŸ‰ All MIPROv2 tests PASSED! Ready for production optimization.")
    else:
        print("âš ï¸  Some tests failed. Check API keys and network connectivity.")


if __name__ == "__main__":
    import asyncio

    asyncio.run(main())
