# Trinity Score: 90.0 (Established by Chancellor)
# packages/afo-core/AFO/chancellor_graph.py
# (LangGraph ÏÉÅÏÑ∏ Íµ¨ÌòÑ - V2: Parallel Strategy & Trinity Gate)
# üß≠ Trinity Score: Áúû98% ÂñÑ99% Áæé95% Â≠ù100%

from typing import Annotated, Any, Literal, TypedDict

from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import END, StateGraph
from langgraph.graph.message import add_messages

# LangChain Memory & VectorStore
try:
    from langchain.memory import VectorStoreRetrieverMemory
    from langchain_openai import OpenAIEmbeddings
    from langchain_qdrant import Qdrant
    from qdrant_client import QdrantClient
except ImportError:
    Qdrant: Any = None  # type: ignore[no-redef]
    VectorStoreRetrieverMemory: Any = None  # type: ignore[no-redef]

# Internal Modules
try:
    from AFO.chancellor.node_04_verdict import emit_verdict
    from AFO.config.antigravity import antigravity
    from AFO.config.settings import get_settings
    from AFO.constitution.constitutional_ai import AFOConstitution
    from AFO.observability.verdict_logger import VerdictLogger
    from services.trinity_calculator import trinity_calculator
    from strategists.sima_yi import goodness_review as sima_yi
    from strategists.zhou_yu import beauty_optimize as zhou_yu

    # Import individual strategists to avoid name conflicts
    from strategists.zhuge_liang import truth_evaluate as zhuge_liang

    # Import individual tigers to avoid name conflicts
    from tigers.guan_yu import truth_guard as guan_yu
    from tigers.huang_zhong import eternity_log as huang_zhong
    from tigers.ma_chao import serenity_deploy as ma_chao
    from tigers.zhang_fei import goodness_gate as zhang_fei
    from tigers.zhao_yun import beauty_craft as zhao_yun

    # Safe imports for circular dependencies
    # Historian and log_sse will be handled gracefully if import fails
    try:
        from utils.history import Historian
        from utils.logging import log_sse
    except ImportError:
        Historian = None  # type: ignore
        log_sse = None  # type: ignore

except ImportError:
    # Set defaults if any imports failed
    class MockConstitution:
        @staticmethod
        def evaluate_compliance(*args, **kwargs):  # noqa: ARG004
            return True, "Mock Compliance"

        @staticmethod
        async def critique_and_revise(*args, **kwargs):  # noqa: ARG004
            return "No critique", args[0], "COMPLIANT"

    AFOConstitution = MockConstitution  # type: ignore[assignment]
    VerdictLogger = None  # type: ignore[assignment]
    emit_verdict = None  # type: ignore[assignment]
    antigravity = None  # type: ignore[assignment]
    get_settings = None  # type: ignore[assignment]
    trinity_calculator = None  # type: ignore[assignment]
    zhuge_liang = None  # type: ignore[assignment]
    sima_yi = None  # type: ignore[assignment]
    zhou_yu = None  # type: ignore[assignment]
    guan_yu = None  # type: ignore[assignment]
    zhang_fei = None  # type: ignore[assignment]
    zhao_yun = None  # type: ignore[assignment]
    ma_chao = None  # type: ignore[assignment]
    huang_zhong = None  # type: ignore[assignment]
    Historian = None  # type: ignore[assignment]
    log_sse = None  # type: ignore[assignment]


# Define mock log_sse if missing
if log_sse is None:

    def log_sse(msg: str) -> None:
        """Mock SSE logging function"""
        print(f"[SSE Mock] {msg}")


# Mock Historian if missing
if Historian is None:

    class MockHistorian:
        @staticmethod
        async def record(*args, **kwargs) -> None:
            """Mock record function"""
            pass

        @staticmethod
        def log_preference(*args, **kwargs) -> None:
            """Mock preference logging function"""
            pass

    Historian = MockHistorian  # type: ignore[assignment]


class ChancellorState(TypedDict):
    """
    State Definition for Chancellor Graph V2.
    Tracks query lifecycle through the 5 Pillars (Áúû¬∑ÂñÑ¬∑Áæé¬∑Â≠ù¬∑Ê∞∏).
    """

    query: str
    messages: Annotated[list[Any], add_messages]
    summary: str  # [ADVANCED/Ê∞∏] conversation summary
    context: dict[str, Any]  # shared context (includes trinity metrics)
    search_results: list[
        dict[str, Any]
    ]  # [ADVANCED/Áúû] raw search results before reranking
    multimodal_slots: dict[str, Any]  # [ADVANCED/Áúû] slots for image/vision data

    # Pillar Assessment
    status: str  # COMPLIANT, BLOCKED, RERANKED, etc.
    risk_score: float  # Derived from Goodness
    trinity_score: float  # SSOT Weighted Total
    analysis_results: Annotated[dict[str, float], lambda a, b: {**(a or {}), **b}]

    # Execution
    results: dict[str, Any]  # Tigers execution outputs
    actions: list[str]  # Sequence of actions taken


# === 1. Graph Definition ===
graph = StateGraph(ChancellorState)

# === 2. Node Definitions ===


async def constitutional_node(state: ChancellorState) -> dict[str, Any]:
    """[Constitution] ÏÑ†(ÂñÑ) ÏµúÏö∞ÏÑ† Í≤ÄÏ¶ù (Self-Refining Gatekeeper)"""
    query = state.get("query", "")

    # Initial Compliance Check (Static/Heuristic)
    is_compliant, reason = AFOConstitution.evaluate_compliance(query, "Intent Analysis")

    if not is_compliant:
        log_sse(f"‚ùå [Constitution] Static Block: {reason}")
        return {"status": "BLOCKED", "trinity_score": 0.0}

    # [ADVANCED CAI] Anthropic-style Self-Critique & Revision Loop
    critique, revised_query, critique_status = (
        await AFOConstitution.critique_and_revise(query, query)
    )

    if critique_status == "REVISED":
        log_sse(
            f"üõ°Ô∏è [Constitution] CAI Refined Query: '{query[:30]}...' -> '{revised_query[:30]}...'"
        )
        log_sse(f"üìù [Constitution] Critique: {critique}")

        # [RLAIF] Record the preference for future alignment (Ê∞∏)
        Historian.log_preference(query, query, revised_query, critique)

        return {
            "query": revised_query,
            "status": "COMPLIANT",
            "context": {**state.get("context", {}), "cai_critique": critique},
        }

    return {"status": "COMPLIANT"}


async def memory_recall_node(state: ChancellorState) -> dict[str, Any]:
    """
    [Memory Recall] ÏòÅ(Ê∞∏) - Í≥ºÍ±∞ Îß•ÎùΩ Î∞è ÏßÄÏãù ÌöåÏÉÅ
    """
    query = state.get("query", "")
    context = state.get("context", {})

    if VectorStoreRetrieverMemory is not None and Qdrant is not None:
        try:
            settings = get_settings()
            client = QdrantClient(url=settings.QDRANT_URL)
            embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

            vectorstore = Qdrant(
                client=client,
                collection_name="obsidian_vault",  # Default Kingdom knowledge
                embeddings=embeddings,
            )

            retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
            memory = VectorStoreRetrieverMemory(retriever=retriever)

            # semantic recall
            history = memory.load_memory_variables({"input": query}).get("history", "")
            if history:
                log_sse(f"üß† [Memory] Recalled {len(history)} chars of context")
                context["semantic_memory"] = history
                state["search_results"] = [
                    {"content": doc.page_content, "metadata": doc.metadata}
                    for doc in retriever.invoke(query)
                ]

        except Exception as e:
            log_sse(f"‚ö†Ô∏è [Memory] Recall failed: {e}")

    return {"context": context, "search_results": state.get("search_results", [])}


async def rerank_node(state: ChancellorState) -> dict[str, Any]:
    """
    [Rerank] Áúû - LLMÏùÑ Ïù¥Ïö©Ìïú Ï†ïÎ∞Ä Ïû¨ÏàúÏúÑ (Precision Reranking)
    """
    query = state.get("query", "")
    results = state.get("search_results", [])

    if not results:
        return {"context": state.get("context", {})}

    try:
        from AFO.julie_cpa.grok_engine import consult_grok

        # Simple LLM Reranking logic: Score each result
        context_str = "\n".join(
            [f"[{i}] {r['content']}" for i, r in enumerate(results[:10])]
        )
        prompt = {"task": "rerank", "query": query, "candidates": context_str}

        # Use Grok for high-fidelity reranking
        await consult_grok(prompt, market_context="rerank_precision", trinity_score=95)

        # Grok output might be mock in sandbox, but we prepare the flow
        log_sse("‚úÖ [Truth] LLM-based Reranking complete")
        # In real scenario, we'd parse analysis and reorder.
        # For MVP, we use the first 3 if they exist or the sorted list if Grok provided indices.

    except Exception as e:
        log_sse(f"‚ö†Ô∏è [Truth] Reranking failed: {e}")

    return {"status": "RERANKED"}


async def summarize_history_node(state: ChancellorState) -> dict[str, Any]:
    """
    [Summary] Ê∞∏ - ÎåÄÌôî ÏöîÏïΩ Î∞è ÏïïÏ∂ï (ConversationSummaryBufferMemory logic)
    """
    messages = state.get("messages", [])
    current_summary = state.get("summary", "")

    # Optimization: Configurable threshold
    threshold = 10
    try:
        settings = get_settings()
        threshold = settings.CHANCELLOR_MAX_MEMORY_ITEMS
    except Exception:
        pass

    if len(messages) > threshold:
        try:
            from AFO.julie_cpa.grok_engine import consult_grok

            log_sse("üîÑ [Eternity] Compressing long-term memory...")

            prompt = {
                "task": "summarize",
                "current_summary": current_summary,
                "new_messages": [m.content for m in messages[-5:]],
            }
            # ... rest of logic

            analysis = await consult_grok(
                prompt, market_context="memory_compression", trinity_score=95
            )

            new_summary = analysis.get("analysis", current_summary)
            return {
                "summary": new_summary,
                "messages": messages[-3:],
            }  # Keep only last 3 in active buffer

        except Exception as e:
            log_sse(f"‚ö†Ô∏è [Eternity] Summarization failed: {e}")

    return {}


# 3 Strategists (Parallel Wrappers)
async def zhuge_node(state: ChancellorState) -> dict[str, Any]:
    """Áúû Strategist Node"""
    score = zhuge_liang({"query": state["query"]}) if callable(zhuge_liang) else 0.5
    return {"analysis_results": {"truth": score}}


async def sima_node(state: ChancellorState) -> dict[str, Any]:
    """ÂñÑ Strategist Node"""
    score = sima_yi({"query": state["query"]}) if callable(sima_yi) else 0.5
    return {"analysis_results": {"goodness": score}}


async def zhou_node(state: ChancellorState) -> dict[str, Any]:
    """Áæé Strategist Node"""
    score = zhou_yu({"query": state["query"]}) if callable(zhou_yu) else 0.5
    return {"analysis_results": {"beauty": score}}


# Trinity Calculation
async def trinity_node(state: ChancellorState) -> dict[str, Any]:
    """
    [Trinity] 5Í∏∞Îë• Ï†êÏàò Ï¢ÖÌï© Î∞è ÏùòÏÇ¨Í≤∞Ï†ï (ÌóåÎ≤ï v1.0 + Amendment 0001 Ï§ÄÏàò)
    """
    results = state.get("analysis_results", {})

    # 1. Áúû/ÂñÑ/Áæé (Strategists)
    t = results.get("truth", 0.5)
    g = results.get("goodness", 0.5)
    b = results.get("beauty", 0.5)

    # 2. Â≠ù/Ê∞∏ (Tigers - Simulation for Scoring)
    s = ma_chao({"query": state["query"], "mode": "eval"}) if callable(ma_chao) else 1.0
    e = (
        huang_zhong("evaluate", {"query": state["query"]})
        if callable(huang_zhong)
        else 1.0
    )

    # Normalize score types
    def normalize(val: Any) -> float:
        if isinstance(val, int | float):
            return float(val)
        return (
            1.0
            if any(
                word in str(val).upper()
                for word in ["COMPLETE", "SAVED", "MODE", "SUCCESS"]
            )
            else 0.5
        )

    raw_scores = [normalize(t), normalize(g), normalize(b), normalize(s), normalize(e)]

    # Calculate Risk Score (1 - Goodness) * 100
    risk_score = (1.0 - normalize(g)) * 100

    if trinity_calculator:
        score = trinity_calculator.calculate_trinity_score(raw_scores)
    else:
        score = sum(raw_scores) * 20

    # === ÌóåÎ≤ï v1.0 + Amendment 0001: Í∞úÎ≥Ñ Ï¶ùÍ±∞ Í±∞Î∂ÄÍ∂å Ï†ÅÏö© ===
    try:
        from AFO.constitution.constitution_v1_0 import VETO_PILLARS, VETO_THRESHOLD

        # Í∞úÎ≥Ñ pillar Ï†êÏàò ÌôïÏù∏ (0-1 scaleÎ°ú Î≥ÄÌôò)
        pillar_scores = {
            "truth": normalize(t),
            "goodness": normalize(g),
            "beauty": normalize(b),
            "serenity": normalize(s),
            "eternity": normalize(e),
        }

        # Í±∞Î∂ÄÍ∂å ÌñâÏÇ¨ pillarÎì§ ÌôïÏù∏ (Áúû¬∑ÂñÑ¬∑Áæé Ï§ë VETO_THRESHOLD ÎØ∏Îßå)
        veto_triggered = False
        low_pillars = []

        for pillar in VETO_PILLARS:
            pillar_score_0_100 = pillar_scores[pillar] * 100  # 0-100 scaleÎ°ú Î≥ÄÌôò
            if pillar_score_0_100 < VETO_THRESHOLD:
                veto_triggered = True
                low_pillars.append(f"{pillar}:{pillar_score_0_100:.1f}")

        # Í±∞Î∂ÄÍ∂å ÌñâÏÇ¨ Ïãú Trinity Score Î¨¥Ìö®Ìôî
        if veto_triggered:
            score = 0.0  # Í∞ïÏ†ú 0Ï†ê Ï≤òÎ¶¨
            log_sse(
                f"üö´ [VETO] Amendment 0001 Activated: Low pillars {low_pillars} (< {VETO_THRESHOLD})"
            )
            log_sse(
                "‚öñÔ∏è [Trinity] VETO: Score forced to 0.0 - Commander approval required"
            )

    except ImportError:
        log_sse("‚ö†Ô∏è [Constitution] v1.0 not loaded - running legacy mode")

    log_sse(f"‚öñÔ∏è [Trinity] Score: {score}/100, Risk: {risk_score}")
    return {
        "trinity_score": score,
        "raw_scores": raw_scores,
        "context": {**state.get("context", {}), "risk_score": risk_score},
    }


# Tigers Execution
async def tigers_node(state: ChancellorState) -> dict[str, Any]:
    """
    [Tigers] 5Ìò∏Ïû•Íµ∞ ÏßëÌñâ (Execution Phase - Ïù¥ÎØ∏ÏßÄ Ïã§Î¨¥ ÏßëÌñâ)
    """
    score = state.get("trinity_score", 0.0)
    risk = state.get("context", {}).get("risk_score", 100.0)
    status = ""
    results = {}

    # DRY_RUN Global Check (Rule #2)
    # Optimization: Use settings for robustness
    is_dry_run = True
    if antigravity:
        is_dry_run = antigravity.DRY_RUN_DEFAULT

    auto_run_threshold = 90.0
    risk_threshold = 10.0
    try:
        settings = get_settings()
        auto_run_threshold = settings.CHANCELLOR_AUTO_RUN_THRESHOLD
        risk_threshold = settings.CHANCELLOR_RISK_THRESHOLD
    except Exception:
        pass

    # AUTO_RUN ÏßëÌñâ (Trinity Score >= Threshold AND Risk Score <= Threshold) - Rule #1
    if score >= auto_run_threshold and risk <= risk_threshold:
        if is_dry_run:
            status = "DRY_RUN ÏßëÌñâ (ÏãúÎÆ¨Î†àÏù¥ÏÖò)"
            log_sse("üß™ [Tigers] DRY_RUN Mode - Simulating Execution")
        else:
            status = "AUTO_RUN ÏßëÌñâ"
            log_sse("üêÖ [Tigers] AUTO_RUN Approved - Executing Full Power")

        # 5Ìò∏Ïû•Íµ∞ Ìò∏Ï∂ú
        if all(
            callable(x) for x in [guan_yu, zhang_fei, zhao_yun, ma_chao, huang_zhong]
        ):
            results = {
                "guan": (
                    guan_yu({"data": state["context"]})
                    if callable(guan_yu)
                    else "Success"
                ),
                "zhang": (
                    zhang_fei(score, state["context"])
                    if callable(zhang_fei)
                    else "Success"
                ),
                "zhao": (
                    zhao_yun("Code Structure", ux_level=2)
                    if callable(zhao_yun)
                    else "Success"
                ),
                "ma": ma_chao(state["context"]) if callable(ma_chao) else "Success",
                "huang": (
                    huang_zhong(state["query"], {"trinity": score})
                    if callable(huang_zhong)
                    else "Success"
                ),
            }
        else:
            results["execution"] = "Success (Simulated)"

    # ASK_COMMANDER (Condition ÎØ∏Ï∂©Ï°±) - Rule #1
    else:
        status = "ASK_COMMANDER - ÌòïÎãò ÏäπÏù∏ ÌïÑÏöî"
        reason = "Low Score" if score < auto_run_threshold else "High Risk"
        log_sse(f"‚úã [Tigers] ASK_COMMANDER - {reason} ({score}/{risk})")

    # [Observability] Emit Verdict Event
    if callable(VerdictLogger) and callable(emit_verdict):
        try:
            # Create logger instance with Redis (Ïã§Ï†ú SSE Ï†ÑÏÜ°ÏùÑ ÏúÑÌï¥)
            from AFO.utils.redis_saver import get_redis_client

            redis_client = get_redis_client()
            logger = VerdictLogger(redis=redis_client)

            # Determine rule_id based on decision logic
            if score >= auto_run_threshold and risk <= risk_threshold:
                rule_id = "R4_AUTORUN_THRESHOLD"
                decision: Literal["AUTO_RUN", "ASK"] = "AUTO_RUN"
            else:
                rule_id = (
                    "R5_FALLBACK_ASK"
                    if score < auto_run_threshold
                    else "R3_VETO_LOW_PILLARS"
                )
                decision = "ASK"

            # Generate trace_id from query or use fallback
            trace_id = f"trc_{hash(state.get('query', 'unknown')) % 10000:04d}"

            # Emit verdict event
            verdict_result = emit_verdict(
                logger=logger,
                trace_id=trace_id,
                decision=decision,
                rule_id=rule_id,
                trinity_score=score,
                risk_score=risk,
                dry_run_default=is_dry_run,
                residual_doubt=bool(risk > 50.0),  # High risk indicates doubt
                extra={
                    "query": state.get("query", ""),
                    "status": status,
                    "reason": reason if "reason" in locals() else None,
                },
            )
            log_sse(
                f"üìä [Verdict] Emitted: {decision} via {rule_id} (Score: {score:.1f}, Risk: {risk:.1f})"
            )
        except Exception as e:
            log_sse(f"‚ö†Ô∏è [Verdict] Logging failed: {e}")

    return {"status": status, "results": results}


# Historian Recording (with Verdict Logging)
async def historian_node(state: ChancellorState) -> dict[str, Any]:
    """
    [Historian] ÏòÅ(Ê∞∏) Í∏∞Î°ù Î≥¥Í¥Ä + Execution Verdict Î°úÍπÖ
    """
    # Legacy historian recording
    # Use Historian safely (could be mock)
    await Historian.record(
        state.get("query", "Unknown"),
        state.get("trinity_score", 0.0),
        state.get("status", "Unknown"),
        metadata=state.get("context", {}),
    )

    # [Observability] Emit execution verdict event
    if callable(VerdictLogger) and callable(emit_verdict):
        try:
            # Create logger instance with Redis (Ïã§Ï†ú SSE Ï†ÑÏÜ°ÏùÑ ÏúÑÌï¥)
            from AFO.utils.redis_saver import get_redis_client

            redis_client = get_redis_client()
            logger = VerdictLogger(redis=redis_client)

            # Generate execution verdict based on results
            results = state.get("results", {})
            trinity_score = state.get("trinity_score", 0.0)

            # Determine execution success/failure
            if results and any("Success" in str(v) for v in results.values()):
                decision: Literal["AUTO_RUN", "ASK"] = "AUTO_RUN"
                rule_id = "R4_AUTORUN_THRESHOLD"
                status = "EXECUTION_SUCCESS"
            elif "DRY_RUN" in state.get("status", ""):
                decision = "AUTO_RUN"
                rule_id = "R1_DRY_RUN_OVERRIDE"
                status = "DRY_RUN_SUCCESS"
            else:
                decision = "ASK"
                rule_id = "R5_FALLBACK_ASK"
                status = "EXECUTION_PENDING"

            # Generate trace_id from query (consistent with node_04)
            trace_id = f"trc_{hash(state.get('query', 'unknown')) % 10000:04d}"

            # Calculate execution metrics (latency, success rate, etc.)
            import time

            execution_time = (
                time.time()
            )  # Placeholder - would be measured in real implementation

            # Emit execution verdict event
            emit_verdict(
                logger=logger,
                trace_id=trace_id,
                decision=decision,
                rule_id=rule_id,
                trinity_score=trinity_score,
                risk_score=0.0,  # Execution phase has no additional risk
                dry_run_default=False,  # Execution already happened
                residual_doubt=False,  # Execution completed
                graph_node_id="node_05_exec",
                step=5,
                extra={
                    "query": state.get("query", ""),
                    "status": status,
                    "execution_results": results,
                    "execution_time": execution_time,
                },
            )
            log_sse(
                f"üìä [Execution Verdict] Emitted: {decision} via {rule_id} (Status: {status})"
            )
        except Exception as e:
            log_sse(f"‚ö†Ô∏è [Execution Verdict] Logging failed: {e}")

    return {}


# === 3. Add Nodes & Edges ===
graph.add_node("constitutional", constitutional_node)
graph.add_node("zhuge", zhuge_node)
graph.add_node("sima", sima_node)
graph.add_node("zhou", zhou_node)
graph.add_node("trinity", trinity_node)
graph.add_node("tigers", tigers_node)
graph.add_node("historian", historian_node)
graph.add_node("memory_recall", memory_recall_node)
graph.add_node("rerank", rerank_node)
graph.add_node("summarize", summarize_history_node)

# Flow Definition
graph.set_entry_point("summarize")  # Start with memory maintenance

graph.add_edge("summarize", "constitutional")


# Conditional Logic: If blocked, go straight to Historian (skip execution)
def check_compliance(state: ChancellorState) -> str:
    if state["status"] == "BLOCKED":
        return "historian"
    return "memory_recall"


graph.add_conditional_edges(
    "constitutional",
    check_compliance,
    {"historian": "historian", "memory_recall": "memory_recall"},
)

# Rerank after recall
graph.add_edge("memory_recall", "rerank")

# After rerank, move to parallel strategies
graph.add_edge("rerank", "zhuge")
graph.add_edge("rerank", "sima")
graph.add_edge("rerank", "zhou")

graph.add_edge("zhuge", "trinity")
graph.add_edge("sima", "trinity")
graph.add_edge("zhou", "trinity")  # Fan-in

graph.add_edge("trinity", "tigers")
graph.add_edge("tigers", "historian")
graph.add_edge("historian", END)

# === 4. Compile ===
# Use AsyncRedisSaver for production persistence (Eternity Ê∞∏)
# Fallback to MemorySaver only if Redis is unavailable
try:
    from langgraph.checkpoint.base import BaseCheckpointSaver

    from AFO.utils.cache_utils import cache
    from AFO.utils.redis_saver import AsyncRedisSaver

    if cache.enabled:
        checkpointer: BaseCheckpointSaver = AsyncRedisSaver()
        log_sse("‚úÖ [Eternity] AsyncRedisSaver Active - Memories are Eternal.")
    else:
        from langgraph.checkpoint.memory import MemorySaver

        checkpointer = MemorySaver()
        log_sse(
            "‚ö†Ô∏è [Eternity Checklist] Redis unavailable, falling back to MemorySaver."
        )
except ImportError:
    from langgraph.checkpoint.memory import MemorySaver

    checkpointer = MemorySaver()
    log_sse("‚ÑπÔ∏è [Memory] MemorySaver active (fallback mode).")

chancellor_graph = graph.compile(checkpointer=checkpointer)


def build_chancellor_graph(checkpointer=None):
    """
    [Factory] Returns the compiled Chancellor Graph.
    Used by routers and verification scripts.
    """
    if checkpointer:
        return graph.compile(checkpointer=checkpointer)
    return chancellor_graph


# Compatibility Aliases for Verification Scripts (Áúû)
chancellor_router_node = constitutional_node  # Entry gate
zhuge_liang_node = zhuge_node
sima_yi_node = sima_node
zhou_yu_node = zhou_node
chancellor_finalize_node = historian_node

# Singleton Export
__all__ = ["ChancellorState", "build_chancellor_graph", "chancellor_graph"]
