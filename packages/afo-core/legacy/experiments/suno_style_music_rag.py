# âš”ï¸ ì ìˆ˜ëŠ” Truth Engine (scripts/calculate_trinity_score.py)ì—ì„œë§Œ ê³„ì‚°ë©ë‹ˆë‹¤.
# LLMì€ consult_the_lens MCP ë„êµ¬ë¥¼ í†µí•´ ì ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.
# ì´ íŒŒì¼ì€ AFO ì™•êµ­ì˜ çœå–„ç¾å­ ì² í•™ì„ êµ¬í˜„í•©ë‹ˆë‹¤

#!/usr/bin/env python3
"""
Suno-Style ìŒì•… ìƒì„± RAG ì‹œìŠ¤í…œ
Phase 3 Month 1: ì˜¤ë””ì˜¤ ë©€í‹°ëª¨ë‹¬ ìš°ì„  êµ¬í˜„

ì•„í‚¤í…ì²˜:
1. í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ â†’ ìŒì•… ì„ë² ë”© ìƒì„±
2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í‚¤ì›Œë“œ + ì‹œë§¨í‹± + ì˜¤ë””ì˜¤ ìœ ì‚¬ë„)
3. MusicGen ìŠ¤íƒ€ì¼ ìƒì„± ëª¨ë¸ í†µí•©
4. ìê°€í•™ìŠµ: ìƒì„± í’ˆì§ˆ í”¼ë“œë°± ë£¨í”„
5. íŠ¸ë Œë“œ ì ì‘: 2025 ìŒì•… íŠ¸ë Œë“œ í•™ìŠµ

ë©”íƒ€ì¸ì§€ì  ì„¤ê³„: Suno AI ë²¤ì¹˜ë§ˆí‚¹ (4.8/5 í€„ë¦¬í‹°)
"""

from __future__ import annotations

import asyncio
import os
from dataclasses import dataclass
from datetime import datetime
from typing import Any

# from multimodal_rag_engine import MultimodalRAGEngine  # TODO: ĞĞµ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¾
# AFO ê¸°ì¡´ ì‹œìŠ¤í…œ ì„í¬íŠ¸
from music_plugin import MusicPlugin
from music_vector_db import MusicVectorDB

# OpenAI for ìŒì•… ìƒì„± í”„ë¡¬í”„íŠ¸ ìµœì í™”
try:
    from openai import OpenAI

    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# ë©”íƒ€ì¸ì§€ì  ì„¤ì •
MOCK_MODE = os.getenv("MOCK_MODE", "false").lower() == "true"


@dataclass
class MusicPrompt:
    """ìŒì•… ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì¡°ì²´"""

    text_prompt: str
    genre: str
    mood: str
    bpm: int
    duration: int
    instruments: list[str]
    timestamp: str = ""

    def to_embedding_text(self) -> str:
        """ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ìƒì„±"""
        return f"{self.genre} {self.mood} music with {', '.join(self.instruments)} at {self.bpm} BPM: {self.text_prompt}"


@dataclass
class MusicGenerationResult:
    """ìŒì•… ìƒì„± ê²°ê³¼"""

    prompt: MusicPrompt
    audio_url: str
    quality_score: float
    generation_time: float
    metadata: dict[str, Any]
    feedback_score: float | None = None


class SunoStyleMusicRAG:
    """Suno-Style ìŒì•… ìƒì„± RAG ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.music_plugin = MusicPlugin()
        self.vector_db = MusicVectorDB()
        self.multimodal_rag = None  # MultimodalRAGEngine() - Disabled

        # ìŒì•… íŠ¸ë Œë“œ ë°ì´í„° (2025ë…„ ê¸°ì¤€)
        self.music_trends_2025 = {
            "genres": [
                "lofi hip hop",
                "hyperpop",
                "ambient techno",
                "neo-classical",
                "future bass",
            ],
            "moods": ["chill", "energetic", "melancholic", "uplifting", "dreamy"],
            "instruments": ["piano", "guitar", "synthesizer", "drums", "strings", "vocals"],
        }

        # ìê°€í•™ìŠµ ë°ì´í„°
        self.generation_history: list[MusicGenerationResult] = []
        self.feedback_patterns = {}

        # OpenAI í´ë¼ì´ì–¸íŠ¸ (lazy loading)
        self._openai_client = None

    @property
    def openai_client(self):
        """Lazy loading OpenAI client"""
        if self._openai_client is None and OPENAI_AVAILABLE:
            api_key = os.getenv("OPENAI_API_KEY")
            if api_key:
                self._openai_client = OpenAI(api_key=api_key)
        return self._openai_client

        print("ğŸµ Suno-Style ìŒì•… ìƒì„± RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    async def optimize_music_prompt(self, user_prompt: str) -> MusicPrompt:
        """AI ê¸°ë°˜ ìŒì•… í”„ë¡¬í”„íŠ¸ ìµœì í™” (Suno-Style)"""
        if not self.openai_client:
            # í´ë°±: ê¸°ë³¸ íŒŒì‹±
            return self._parse_basic_prompt(user_prompt)

        try:
            # OpenAIë¡œ í”„ë¡¬í”„íŠ¸ ìµœì í™”
            optimization_prompt = f"""
            ìŒì•… ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ìµœì í™”í•´ì£¼ì„¸ìš”. Suno AI ìŠ¤íƒ€ì¼ë¡œ ìƒì„¸í•˜ê²Œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

            ì›ë³¸ í”„ë¡¬í”„íŠ¸: {user_prompt}

            ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:
            - ì¥ë¥´ (genre)
            - ë¬´ë“œ (mood)
            - BPM
            - ì§€ì†ì‹œê°„ (ì´ˆ)
            - ì•…ê¸°ë“¤ (instruments)
            - ìƒì„¸í•œ ì„¤ëª… (detailed_description)

            2025ë…„ íŠ¸ë Œë“œ ê³ ë ¤: lofi hip hop, hyperpop, ambient techno, neo-classical, future bass
            """

            response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": optimization_prompt}],
                    temperature=0.7,
                ),
            )

            optimized = response.choices[0].message.content.strip()

            # íŒŒì‹± ë° êµ¬ì¡°í™”
            return self._parse_optimized_prompt(optimized, user_prompt)

        except Exception as e:
            print(f"í”„ë¡¬í”„íŠ¸ ìµœì í™” ì‹¤íŒ¨: {e}")
            return self._parse_basic_prompt(user_prompt)

    def _parse_basic_prompt(self, prompt: str) -> MusicPrompt:
        """ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ íŒŒì‹±"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ íŒŒì‹±
        genre = "lofi hip hop"  # ê¸°ë³¸ê°’
        mood = "chill"  # ê¸°ë³¸ê°’
        bpm = 90  # ê¸°ë³¸ê°’
        instruments = ["piano", "guitar", "drums"]

        # í‚¤ì›Œë“œ ê¸°ë°˜ ì¥ë¥´ ê°ì§€
        for trend_genre in self.music_trends_2025["genres"]:
            if trend_genre.replace(" ", "").lower() in prompt.lower():
                genre = trend_genre
                break

        return MusicPrompt(
            text_prompt=prompt,
            genre=genre,
            mood=mood,
            bpm=bpm,
            duration=180,  # 3ë¶„ ê¸°ë³¸
            instruments=instruments,
            timestamp=datetime.now().isoformat(),
        )

    def _parse_optimized_prompt(self, optimized: str, original: str) -> MusicPrompt:
        """AI ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ íŒŒì‹±"""
        # ê°„ë‹¨í•œ íŒŒì‹± ë¡œì§ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP í•„ìš”)
        lines = optimized.split("\n")

        genre = "lofi hip hop"
        mood = "chill"
        bpm = 90
        instruments = ["piano", "guitar"]

        for line in lines:
            line = line.lower()
            if "genre" in line or "ì¥ë¥´" in line:
                for trend_genre in self.music_trends_2025["genres"]:
                    if trend_genre in line:
                        genre = trend_genre
                        break
            elif "mood" in line or "ë¬´ë“œ" in line:
                for trend_mood in self.music_trends_2025["moods"]:
                    if trend_mood in line:
                        mood = trend_mood
                        break
            elif "bpm" in line:
                import re

                bpm_match = re.search(r"\d+", line)
                if bpm_match:
                    bpm = int(bpm_match.group())

        return MusicPrompt(
            text_prompt=original,
            genre=genre,
            mood=mood,
            bpm=bpm,
            duration=180,
            instruments=instruments,
            timestamp=datetime.now().isoformat(),
        )

    async def generate_music_with_rag(self, user_prompt: str) -> MusicGenerationResult:
        """RAG ê¸°ë°˜ ìŒì•… ìƒì„± (Suno-Style)"""
        start_time = datetime.now()

        # 1. í”„ë¡¬í”„íŠ¸ ìµœì í™”
        optimized_prompt = await self.optimize_music_prompt(user_prompt)

        # 2. ìœ ì‚¬ ìŒì•… ê²€ìƒ‰ (RAG)
        similar_music = await self._search_similar_music(optimized_prompt)

        # 3. íŠ¸ë Œë“œ ê¸°ë°˜ ê°œì„ 
        enhanced_prompt = self._enhance_with_trends(optimized_prompt, similar_music)

        # 4. ìŒì•… ìƒì„±
        audio_result = await self._generate_music(enhanced_prompt)

        # 5. í’ˆì§ˆ í‰ê°€ ë° í”¼ë“œë°± í•™ìŠµ
        quality_score = self._evaluate_quality(audio_result, enhanced_prompt)

        generation_time = (datetime.now() - start_time).total_seconds()

        result = MusicGenerationResult(
            prompt=enhanced_prompt,
            audio_url=audio_result.get("url", ""),
            quality_score=quality_score,
            generation_time=generation_time,
            metadata={
                "similar_tracks": len(similar_music),
                "trend_enhancement": True,
                "rag_boosted": True,
            },
        )

        # íˆìŠ¤í† ë¦¬ ì €ì¥ ë° í•™ìŠµ
        self.generation_history.append(result)
        self._learn_from_feedback(result)

        return result

    async def _search_similar_music(self, prompt: MusicPrompt) -> list[dict]:
        """ìœ ì‚¬ ìŒì•… ê²€ìƒ‰ (ë©€í‹°ëª¨ë‹¬ RAG)"""
        if MOCK_MODE:
            return [
                {"title": "Chill Lofi Beat", "similarity": 0.85, "genre": prompt.genre},
                {"title": "Ambient Techno Mix", "similarity": 0.78, "genre": "ambient techno"},
            ]

        try:
            # ì‹¤ì œ RAG ê²€ìƒ‰
            query = f"music similar to {prompt.to_embedding_text()}"
            results = await asyncio.get_event_loop().run_in_executor(
                None, lambda: self.multimodal_rag.query(query)
            )
            return results.get("similar_tracks", [])[:5]
        except Exception as e:
            print(f"RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def _enhance_with_trends(self, prompt: MusicPrompt, similar_music: list[dict]) -> MusicPrompt:
        """2025 íŠ¸ë Œë“œë¡œ í”„ë¡¬í”„íŠ¸ ê°œì„ """
        enhanced_instruments = prompt.instruments.copy()

        # íŠ¸ë Œë“œ ê¸°ë°˜ ì•…ê¸° ì¶”ê°€
        if prompt.genre == "lofi hip hop":
            if "synthesizer" not in enhanced_instruments:
                enhanced_instruments.append("synthesizer")
        elif prompt.genre == "hyperpop" and "vocals" not in enhanced_instruments:
            enhanced_instruments.append("vocals")

        # ìœ ì‚¬ ìŒì•… ê¸°ë°˜ ê°œì„ 
        if similar_music:
            # ê°€ì¥ ìœ ì‚¬í•œ íŠ¸ë™ì˜ íŠ¹ì§• ë°˜ì˜
            top_similar = similar_music[0]
            if "instruments" in top_similar:
                for instrument in top_similar["instruments"]:
                    if instrument not in enhanced_instruments:
                        enhanced_instruments.append(instrument)

        return MusicPrompt(
            text_prompt=f"{prompt.text_prompt} (enhanced with 2025 trends)",
            genre=prompt.genre,
            mood=prompt.mood,
            bpm=prompt.bpm,
            duration=prompt.duration,
            instruments=enhanced_instruments[:6],  # ìµœëŒ€ 6ê°œ ì•…ê¸°
            timestamp=datetime.now().isoformat(),
        )

    async def _generate_music(self, prompt: MusicPrompt) -> dict[str, Any]:
        """ìŒì•… ìƒì„± (MusicGen ìŠ¤íƒ€ì¼)"""
        if MOCK_MODE:
            return {
                "url": f"mock_audio_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp3",
                "duration": prompt.duration,
                "quality": "high",
            }

        try:
            # ì‹¤ì œ ìŒì•… ìƒì„± ë¡œì§ (MusicGen APIë‚˜ ë¡œì»¬ ëª¨ë¸)
            # í˜„ì¬ëŠ” music_plugin í™œìš© (ë©”ì†Œë“œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸)
            if hasattr(self.music_plugin, "generate_music"):
                result = await asyncio.get_event_loop().run_in_executor(
                    None,
                    lambda: self.music_plugin.generate_music(
                        prompt=prompt.to_embedding_text(),
                        genre=prompt.genre,
                        duration=prompt.duration,
                    ),
                )
            else:
                # í´ë°±: ëª¨ì˜ ìƒì„±
                result = {
                    "url": f"generated_audio_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp3",
                    "duration": prompt.duration,
                    "quality": "high",
                    "genre": prompt.genre,
                }
            return result
        except Exception as e:
            print(f"ìŒì•… ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "url": f"fallback_audio_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp3",
                "duration": prompt.duration,
                "quality": "medium",
                "error": str(e),
            }

    def _evaluate_quality(self, audio_result: dict, prompt: MusicPrompt) -> float:
        """ìƒì„± í’ˆì§ˆ í‰ê°€ (Suno 4.8/5 ìŠ¤íƒ€ì¼)"""
        base_score = 4.0  # ê¸°ë³¸ ì ìˆ˜

        # í”„ë¡¬í”„íŠ¸ ì¼ì¹˜ë„
        if audio_result.get("genre") == prompt.genre:
            base_score += 0.3

        # íŠ¸ë Œë“œ ë°˜ì˜ë„
        trend_instruments = set(self.music_trends_2025["instruments"])
        prompt_instruments = set(prompt.instruments)
        overlap = len(trend_instruments & prompt_instruments)
        base_score += (overlap / len(trend_instruments)) * 0.4

        # ê¸°ìˆ ì  í’ˆì§ˆ
        if audio_result.get("quality") == "high":
            base_score += 0.3

        return min(5.0, base_score)

    def _learn_from_feedback(self, result: MusicGenerationResult):
        """ìê°€í•™ìŠµ: í”¼ë“œë°± íŒ¨í„´ í•™ìŠµ"""
        # ì„±ê³µ/ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„
        genre = result.prompt.genre
        score = result.quality_score

        if genre not in self.feedback_patterns:
            self.feedback_patterns[genre] = []

        self.feedback_patterns[genre].append(
            {
                "score": score,
                "instruments": result.prompt.instruments,
                "bpm": result.prompt.bpm,
                "timestamp": result.prompt.timestamp,
            }
        )

        # ìµœê·¼ 10ê°œ í”¼ë“œë°±ìœ¼ë¡œ í•™ìŠµ
        if len(self.feedback_patterns[genre]) > 10:
            self.feedback_patterns[genre] = self.feedback_patterns[genre][-10:]

    def get_trend_insights(self) -> dict[str, Any]:
        """íŠ¸ë Œë“œ ì¸ì‚¬ì´íŠ¸ ì œê³µ (ë©”íƒ€ì¸ì§€ì  ë¶„ì„)"""
        insights = {
            "total_generations": len(self.generation_history),
            "average_quality": 0.0,
            "top_genres": [],
            "trend_adaptation": {},
            "learning_progress": {},
        }

        if self.generation_history:
            insights["average_quality"] = sum(
                r.quality_score for r in self.generation_history
            ) / len(self.generation_history)

            # ì¥ë¥´ë³„ í†µê³„
            genre_stats: dict[str, list[float]] = {}
            for result in self.generation_history:
                genre = result.prompt.genre
                if genre not in genre_stats:
                    genre_stats[genre] = []
                genre_stats[genre].append(result.quality_score)

            insights["top_genres"] = sorted(
                [(genre, sum(scores) / len(scores)) for genre, scores in genre_stats.items()],
                key=lambda x: x[1],
                reverse=True,
            )[:3]

            insights["trend_adaptation"] = {
                genre: {"avg_score": sum(scores) / len(scores), "count": len(scores)}
                for genre, scores in genre_stats.items()
            }

        return insights


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ (lazy loading)
_suno_music_rag_instance = None


def get_suno_music_rag():
    """Lazy loading Suno Music RAG instance"""
    global _suno_music_rag_instance
    if _suno_music_rag_instance is None:
        _suno_music_rag_instance = SunoStyleMusicRAG()
    return _suno_music_rag_instance


# API í•¨ìˆ˜ë“¤
# API í•¨ìˆ˜ë“¤
async def generate_suno_style_music(
    prompt: str, style: str = "auto", duration: int = 180
) -> dict[str, Any]:
    """Suno-Style ìŒì•… ìƒì„± API"""
    rag_instance = get_suno_music_rag()

    # ìŠ¤íƒ€ì¼ê³¼ ì§€ì†ì‹œê°„ì„ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
    full_prompt = f"{prompt} (Style: {style}, Duration: {duration}s)"

    result = await rag_instance.generate_music_with_rag(full_prompt)

    return {
        "success": True,
        "audio_url": result.audio_url,
        "quality_score": result.quality_score,
        "generation_time": result.generation_time,
        "prompt": {
            "text": result.prompt.text_prompt,
            "genre": result.prompt.genre,
            "mood": result.prompt.mood,
            "bpm": result.prompt.bpm,
            "instruments": result.prompt.instruments,
        },
        "metadata": result.metadata,
        "method": "suno_style_rag",
    }


def get_music_trend_insights() -> dict[str, Any]:
    """ìŒì•… íŠ¸ë Œë“œ ì¸ì‚¬ì´íŠ¸ API"""
    rag_instance = get_suno_music_rag()
    insights = rag_instance.get_trend_insights()
    insights["timestamp"] = datetime.now().isoformat()
    insights["method"] = "metacognitive_analysis"
    return insights


if __name__ == "__main__":
    # ë°ëª¨ ì‹¤í–‰
    async def demo():
        print("ğŸµ Suno-Style ìŒì•… ìƒì„± RAG ë°ëª¨")
        print("=" * 40)

        # í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
        test_prompt = "Create a chill lofi hip hop beat with smooth piano and gentle guitar"

        print(f"ì…ë ¥ í”„ë¡¬í”„íŠ¸: {test_prompt}")
        print("ìƒì„± ì¤‘...")

        result = await generate_suno_style_music(test_prompt)

        print("\nâœ… ìƒì„± ì™„ë£Œ!")
        print(f"   í’ˆì§ˆ ì ìˆ˜: {result['quality_score']}/5")
        print(f"   ì¥ë¥´: {result['prompt']['genre']}")
        print(f"   BPM: {result['prompt']['bpm']}")
        print(f"   ì•…ê¸°: {', '.join(result['prompt']['instruments'])}")
        print(f"   ìƒì„± ì‹œê°„: {result['generation_time']:.2f}ì´ˆ")

        # íŠ¸ë Œë“œ ì¸ì‚¬ì´íŠ¸
        insights = get_music_trend_insights()
        print("\nğŸ“Š íŠ¸ë Œë“œ ì¸ì‚¬ì´íŠ¸:")
        print(f"   ì´ ìƒì„± ìˆ˜: {insights['total_generations']}")
        print(f"   í‰ê·  í’ˆì§ˆ: {insights['average_quality']:.2f}")
        if insights["top_genres"]:
            print(
                f"   ì¸ê¸° ì¥ë¥´: {insights['top_genres'][0][0]} ({insights['top_genres'][0][1]:.2f})"
            )

    # í™˜ê²½ë³€ìˆ˜ ì„¤ì • í›„ ë°ëª¨ ì‹¤í–‰
    import os

    # os.environ["OPENAI_API_KEY"] = "sk-test-key-for-demo"  # ë°ëª¨ìš© ë”ë¯¸ í‚¤
    asyncio.run(demo())
