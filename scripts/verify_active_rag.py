#!/usr/bin/env python3
"""
Active RAG ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ - RAG ì‹œìŠ¤í…œì˜ ë™ì  ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ë° ì‘ë‹µ ìƒì„± ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

AFO ì™•êµ­ TICKET-002: Active RAG ê²€ì¦ì„ ìœ„í•œ ì¦ê±° ìƒì„±ê¸°
RAG ì‹œìŠ¤í…œì˜ ì‹¤ì‹œê°„ ê²€ìƒ‰, ì»¨í…ìŠ¤íŠ¸ í†µí•©, ì‘ë‹µ ìƒì„± ê¸°ëŠ¥ ê²€ì¦

ì‚¬ìš©ë²•:
    python scripts/verify_active_rag.py

ì¶œë ¥:
    - artifacts/active_rag_verification_[timestamp]/ ì¦ê±° í´ë” ìƒì„±
    - manifest.sha256ë¡œ ì¦ê±° ë¬´ê²°ì„± ë³´ì¥
"""

import asyncio
import json
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List


# AFO ì™•êµ­ íŒ¨í‚¤ì§€ ì„í¬íŠ¸ (ê°€ìš©í•œ ê²ƒë§Œ)
try:
    from afo.rag_flag import determine_rag_mode

    RAG_FLAG_AVAILABLE = True
except ImportError:
    RAG_FLAG_AVAILABLE = False
    print("WARNING: RAG flag functions not available")

try:
    from afo.rag_cache import RAGCache

    RAG_CACHE_AVAILABLE = True
except ImportError:
    RAG_CACHE_AVAILABLE = False
    print("WARNING: RAG cache not available")

try:
    from afo.rag_chunking import RAGChunking

    RAG_CHUNKING_AVAILABLE = True
except ImportError:
    RAG_CHUNKING_AVAILABLE = False
    print("WARNING: RAG chunking not available")


class ActiveRAGVerifier:
    """Active RAG ê¸°ëŠ¥ ê²€ì¦ê¸°"""

    def __init__(self):
        self.timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        self.evidence_dir = Path(f"artifacts/active_rag_verification_{self.timestamp}")
        self.evidence_dir.mkdir(parents=True, exist_ok=True)

        self.results = {
            "test_timestamp": self.timestamp,
            "rag_components_available": {
                "rag_flag": RAG_FLAG_AVAILABLE,
                "rag_cache": RAG_CACHE_AVAILABLE,
                "rag_chunking": RAG_CHUNKING_AVAILABLE,
            },
            "tests": [],
            "overall_status": "unknown",
        }

    def log(self, message: str) -> None:
        """ì¦ê±° ë¡œê·¸ ê¸°ë¡"""
        timestamp = datetime.now().isoformat()
        log_entry = f"[{timestamp}] {message}"

        log_file = self.evidence_dir / "verification_log.txt"
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(log_entry + "\n")

        print(message)

    async def test_rag_flag_determination(self) -> dict[str, Any]:
        """RAG ëª¨ë“œ ê²°ì • ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        test_name = "rag_flag_determination"
        self.log(f"Starting test: {test_name}")

        result = {"test_name": test_name, "status": "unknown", "details": {}, "error": None}

        try:
            if not RAG_FLAG_AVAILABLE:
                result["status"] = "skipped"
                result["details"]["reason"] = "RAG flag functions not available"
                return result

            # ì‹¤ì œ determine_rag_mode í•¨ìˆ˜ì˜ í—¤ë” ê¸°ë°˜ ë™ì‘ì„ í…ŒìŠ¤íŠ¸
            test_cases = [
                {
                    "name": "No headers (default shadow_only)",
                    "headers": None,
                    "expected_mode": "shadow_only",
                    "expected_applied": False,
                },
                {
                    "name": "Kill switch active",
                    "headers": None,
                    "env_override": {"AFO_RAG_KILL_SWITCH": "1"},
                    "expected_mode": "killed",
                    "expected_applied": False,
                },
                {
                    "name": "Force ON via header",
                    "headers": {"X-AFO-RAG": "1"},
                    "expected_mode": "forced_on",
                    "expected_applied": True,
                },
                {
                    "name": "Force OFF via header",
                    "headers": {"X-AFO-RAG": "0"},
                    "expected_mode": "forced_off",
                    "expected_applied": False,
                },
                {
                    "name": "Flag enabled via ENV",
                    "headers": None,
                    "env_override": {"AFO_RAG_FLAG_ENABLED": "1"},
                    "expected_mode": "flag",
                    "expected_applied": True,
                },
            ]

            results = []
            for i, test_case in enumerate(test_cases):
                try:
                    # í™˜ê²½ë³€ìˆ˜ ì„ì‹œ ì„¤ì • (ìˆëŠ” ê²½ìš°)
                    env_backup = {}
                    if "env_override" in test_case:
                        for key, value in test_case["env_override"].items():
                            env_backup[key] = os.environ.get(key)
                            os.environ[key] = value

                    # determine_rag_mode í˜¸ì¶œ
                    mode_result = determine_rag_mode(test_case["headers"])
                    mode = mode_result["mode"]
                    applied = mode_result["applied"]

                    # í™˜ê²½ë³€ìˆ˜ ë³µì›
                    for key, value in env_backup.items():
                        if value is None:
                            os.environ.pop(key, None)
                        else:
                            os.environ[key] = value

                    results.append({
                        "case": i + 1,
                        "name": test_case["name"],
                        "determined_mode": mode,
                        "expected_mode": test_case["expected_mode"],
                        "determined_applied": applied,
                        "expected_applied": test_case["expected_applied"],
                        "mode_match": mode == test_case["expected_mode"],
                        "applied_match": applied == test_case["expected_applied"],
                        "match": mode == test_case["expected_mode"]
                        and applied == test_case["expected_applied"],
                    })
                except Exception as e:
                    results.append({
                        "case": i + 1,
                        "name": test_case["name"],
                        "error": str(e),
                        "match": False,
                    })

            result["details"]["test_cases_run"] = len(results)
            result["details"]["successful_cases"] = sum(1 for r in results if r.get("match", False))
            result["details"]["results"] = results

            if result["details"]["successful_cases"] == len(results):
                result["status"] = "passed"
            else:
                result["status"] = "failed"
                result["error"] = (
                    f"Only {result['details']['successful_cases']}/{len(results)} cases passed"
                )

        except Exception as e:
            result["status"] = "failed"
            result["error"] = str(e)
            self.log(f"Test failed: {e}")

        return result

    async def test_rag_cache_operations(self) -> dict[str, Any]:
        """RAG ìºì‹œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        test_name = "rag_cache_operations"
        self.log(f"Starting test: {test_name}")

        result = {"test_name": test_name, "status": "unknown", "details": {}, "error": None}

        try:
            if not RAG_CACHE_AVAILABLE:
                result["status"] = "skipped"
                result["details"]["reason"] = "RAG cache not available"
                return result

            # ìºì‹œ ì´ˆê¸°í™” ì‹œë„
            cache = RAGCache()
            result["details"]["cache_initialized"] = True

            # ê¸°ë³¸ ìºì‹œ ì—°ì‚° í…ŒìŠ¤íŠ¸
            test_key = "test_query_123"
            test_value = {
                "query": "test query",
                "results": ["result1", "result2"],
                "timestamp": datetime.now().isoformat(),
            }

            # ì €ì¥ í…ŒìŠ¤íŠ¸
            cache.set(test_key, test_value)
            result["details"]["cache_set_success"] = True

            # ì¡°íšŒ í…ŒìŠ¤íŠ¸
            retrieved = cache.get(test_key)
            result["details"]["cache_get_success"] = retrieved is not None
            result["details"]["cache_data_match"] = retrieved == test_value

            # ì‚­ì œ í…ŒìŠ¤íŠ¸
            cache.delete(test_key)
            deleted_check = cache.get(test_key)
            result["details"]["cache_delete_success"] = deleted_check is None

            # ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸
            all_success = all([
                result["details"]["cache_set_success"],
                result["details"]["cache_get_success"],
                result["details"]["cache_data_match"],
                result["details"]["cache_delete_success"],
            ])

            result["status"] = "passed" if all_success else "failed"

        except Exception as e:
            result["status"] = "failed"
            result["error"] = str(e)
            self.log(f"Test failed: {e}")

        return result

    async def test_rag_chunking_operations(self) -> dict[str, Any]:
        """RAG ì²­í‚¹ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        test_name = "rag_chunking_operations"
        self.log(f"Starting test: {test_name}")

        result = {"test_name": test_name, "status": "unknown", "details": {}, "error": None}

        try:
            if not RAG_CHUNKING_AVAILABLE:
                result["status"] = "skipped"
                result["details"]["reason"] = "RAG chunking not available"
                return result

            # ì²­í‚¹ ì´ˆê¸°í™”
            chunking = RAGChunking()
            result["details"]["chunking_initialized"] = True

            # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
            test_text = """
            This is a test document for RAG chunking verification.
            It contains multiple sentences and paragraphs.
            The chunking system should be able to split this text
            into meaningful chunks for retrieval-augmented generation.
            Each chunk should maintain semantic coherence.
            """.strip()

            # ì²­í‚¹ ì‹¤í–‰
            chunks = chunking.chunk_text(test_text)
            result["details"]["chunks_created"] = len(chunks)
            result["details"]["original_text_length"] = len(test_text)

            # ì²­í¬ ê²€ì¦
            total_chunk_length = sum(len(chunk) for chunk in chunks)
            result["details"]["total_chunk_length"] = total_chunk_length
            result["details"]["length_preserved"] = (
                total_chunk_length >= len(test_text) * 0.9
            )  # 90% ë³´ì¡´

            # ì²­í¬ ë‚´ìš© ê²€ì¦
            all_chunks_have_content = all(len(chunk.strip()) > 0 for chunk in chunks)
            result["details"]["all_chunks_have_content"] = all_chunks_have_content

            # ì²­í¬ í¬ê¸° ë¶„í¬ í™•ì¸
            chunk_sizes = [len(chunk) for chunk in chunks]
            result["details"]["chunk_sizes"] = chunk_sizes
            result["details"]["avg_chunk_size"] = (
                sum(chunk_sizes) / len(chunk_sizes) if chunk_sizes else 0
            )

            # í…ŒìŠ¤íŠ¸ í†µê³¼ ì¡°ê±´
            basic_tests_pass = (
                len(chunks) > 0
                and result["details"]["length_preserved"]
                and all_chunks_have_content
            )

            result["status"] = "passed" if basic_tests_pass else "failed"

        except Exception as e:
            result["status"] = "failed"
            result["error"] = str(e)
            self.log(f"Test failed: {e}")

        return result

    async def test_rag_integration_flow(self) -> dict[str, Any]:
        """RAG í†µí•© í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
        test_name = "rag_integration_flow"
        self.log(f"Starting test: {test_name}")

        result = {"test_name": test_name, "status": "unknown", "details": {}, "error": None}

        try:
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì»´í¬ë„ŒíŠ¸ í™•ì¸
            available_components = []
            if RAG_FLAG_AVAILABLE:
                available_components.append("flag")
            if RAG_CACHE_AVAILABLE:
                available_components.append("cache")
            if RAG_CHUNKING_AVAILABLE:
                available_components.append("chunking")

            result["details"]["available_components"] = available_components

            if not available_components:
                result["status"] = "skipped"
                result["details"]["reason"] = "No RAG components available"
                return result

            # í†µí•© í”Œë¡œìš° ì‹œë®¬ë ˆì´ì…˜
            test_query = "How does RAG improve LLM responses?"
            test_context = """
            RAG (Retrieval-Augmented Generation) improves LLM responses by:
            1. Retrieving relevant information from external knowledge sources
            2. Augmenting the original query with retrieved context
            3. Generating more accurate and grounded responses
            4. Reducing hallucinations and improving factual accuracy
            """.strip()

            flow_steps = []

            # 1. RAG ëª¨ë“œ ê²°ì • (ìˆëŠ” ê²½ìš°)
            if RAG_FLAG_AVAILABLE:
                mode_result = determine_rag_mode()
                mode = mode_result["mode"]
                flow_steps.append({"step": "mode_determination", "mode": mode, "success": True})
            else:
                flow_steps.append({"step": "mode_determination", "skipped": True})

            # 2. ì»¨í…ìŠ¤íŠ¸ ì²­í‚¹ (ìˆëŠ” ê²½ìš°)
            if RAG_CHUNKING_AVAILABLE:
                chunking = RAGChunking()
                chunks = chunking.chunk_text(test_context)
                flow_steps.append({
                    "step": "chunking",
                    "chunks_created": len(chunks),
                    "success": len(chunks) > 0,
                })
            else:
                flow_steps.append({"step": "chunking", "skipped": True})

            # 3. ìºì‹œ ì—°ì‚° (ìˆëŠ” ê²½ìš°)
            if RAG_CACHE_AVAILABLE:
                cache = RAGCache()
                cache_key = f"test_{hash(test_query) % 1000}"
                cache.set(
                    cache_key,
                    {"query": test_query, "chunks": chunks if "chunks" in locals() else []},
                )
                cached_data = cache.get(cache_key)
                flow_steps.append({
                    "step": "caching",
                    "cache_set": True,
                    "cache_get": cached_data is not None,
                    "success": cached_data is not None,
                })
                cache.delete(cache_key)
            else:
                flow_steps.append({"step": "caching", "skipped": True})

            result["details"]["flow_steps"] = flow_steps
            result["details"]["flow_completion"] = sum(
                1 for step in flow_steps if step.get("success", False) or step.get("skipped", False)
            )

            # í†µí•© í”Œë¡œìš° ì„±ê³µ íŒì • (ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹¨ê³„ë“¤ì´ ì„±ê³µ)
            successful_steps = sum(1 for step in flow_steps if step.get("success", False))
            skipped_steps = sum(1 for step in flow_steps if step.get("skipped", False))
            total_steps = len(flow_steps)

            if successful_steps + skipped_steps == total_steps:
                result["status"] = "passed"
            else:
                result["status"] = "failed"
                result["error"] = (
                    f"Flow incomplete: {successful_steps}/{total_steps} steps successful"
                )

        except Exception as e:
            result["status"] = "failed"
            result["error"] = str(e)
            self.log(f"Test failed: {e}")

        return result

    async def run_all_tests(self) -> dict[str, Any]:
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        self.log("Starting Active RAG verification tests")
        self.log(f"Evidence directory: {self.evidence_dir}")

        tests = [
            self.test_rag_flag_determination(),
            self.test_rag_cache_operations(),
            self.test_rag_chunking_operations(),
            self.test_rag_integration_flow(),
        ]

        completed_tests = []
        for test_coro in tests:
            test_result = await test_coro
            completed_tests.append(test_result)
            self.log(f"Test {test_result['test_name']}: {test_result['status']}")

        self.results["tests"] = completed_tests

        # ì „ì²´ ìƒíƒœ íŒì •
        statuses = [test["status"] for test in completed_tests]
        if "failed" in statuses:
            self.results["overall_status"] = "failed"
        elif all(status in ["passed", "skipped"] for status in statuses):
            self.results["overall_status"] = "passed"
        else:
            self.results["overall_status"] = "partial"

        self.log(f"Overall status: {self.results['overall_status']}")
        return self.results

    def save_results(self) -> None:
        """ê²°ê³¼ë¥¼ ì¦ê±° íŒŒì¼ë¡œ ì €ì¥"""
        # JSON ê²°ê³¼ ì €ì¥
        results_file = self.evidence_dir / "test_results.json"
        with open(results_file, "w", encoding="utf-8") as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)

        # ìš”ì•½ íŒŒì¼ ìƒì„±
        summary_file = self.evidence_dir / "test_summary.txt"
        with open(summary_file, "w", encoding="utf-8") as f:
            f.write("Active RAG Verification Summary\n")
            f.write("=" * 40 + "\n\n")
            f.write(f"Timestamp: {self.results['test_timestamp']}\n")
            f.write(f"RAG Components Available: {self.results['rag_components_available']}\n")
            f.write(f"Overall Status: {self.results['overall_status']}\n\n")

            f.write("Test Results:\n")
            for test in self.results["tests"]:
                f.write(f"- {test['test_name']}: {test['status']}\n")
                if test.get("error"):
                    f.write(f"  Error: {test['error']}\n")

        # manifest.sha256 ìƒì„±
        import hashlib

        manifest_file = self.evidence_dir / "manifest.sha256"
        with open(manifest_file, "w", encoding="utf-8") as f:
            for file_path in sorted(self.evidence_dir.glob("*")):
                if file_path.name != "manifest.sha256":
                    hash_sha256 = hashlib.sha256()
                    with open(file_path, "rb") as file:
                        for chunk in iter(lambda: file.read(4096), b""):
                            hash_sha256.update(chunk)
                    f.write(f"{hash_sha256.hexdigest()}  {file_path.name}\n")

        self.log(f"Evidence saved to {self.evidence_dir}")


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ”¥ AFO Kingdom Active RAG Verification")
    print("=" * 50)

    verifier = ActiveRAGVerifier()
    results = await verifier.run_all_tests()
    verifier.save_results()

    print("\n" + "=" * 50)
    print(f"Overall Status: {results['overall_status']}")
    print(f"Evidence: {verifier.evidence_dir}")

    # ì¢…ë£Œ ì½”ë“œ
    if results["overall_status"] == "passed":
        print("âœ… Active RAG verification PASSED")
        return 0
    if results["overall_status"] == "partial":
        print("âš ï¸  Active RAG verification PARTIAL")
        return 1
    print("âŒ Active RAG verification FAILED")
    return 2


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
