#!/usr/bin/env python3
"""
Trinity Score Check Script for Pre-commit Hooks
Sequential Thinking: ì½”ë“œ í’ˆì§ˆ ìë™ ê²€ì¦ ì‹œìŠ¤í…œ êµ¬ì¶•
"""

import ast
import os
import sys
from pathlib import Path


# Trinity Score ê°€ì¤‘ì¹˜
TRINITY_WEIGHTS = {
    "truth": 0.35,  # ê¸°ìˆ ì  ì •í™•ì„±
    "goodness": 0.35,  # ì•ˆì „ì„±ê³¼ ì‹ ë¢°ì„±
    "beauty": 0.20,  # êµ¬ì¡°ì  ìš°ì•„í•¨
    "serenity": 0.08,  # í‰ì˜¨í•¨
    "eternity": 0.02,  # ì§€ì†ê°€ëŠ¥ì„±
}

# ìµœì†Œ ìš”êµ¬ ì‚¬í•­
MIN_REQUIREMENTS = {
    "type_coverage": 70.0,  # íƒ€ì… ì»¤ë²„ë¦¬ì§€ 70%
    "mypy_errors": 5,  # MyPy ì˜¤ë¥˜ 5ê°œ ì´í•˜
    "complexity_limit": 15,  # ë³µì¡ë„ ì œí•œ
    "trinity_score": 80.0,  # Trinity Score 80ì  ì´ìƒ
}


class TrinityScoreChecker:
    """
    Trinity Score ê²€ì¦ í´ë˜ìŠ¤
    Sequential Thinking: ë‹¨ê³„ë³„ ì½”ë“œ í’ˆì§ˆ í‰ê°€
    """

    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.results = {
            "truth": {"score": 0.0, "details": []},
            "goodness": {"score": 0.0, "details": []},
            "beauty": {"score": 0.0, "details": []},
            "serenity": {"score": 0.0, "details": []},
            "eternity": {"score": 0.0, "details": []},
        }
        self.overall_score = 0.0

    def analyze_codebase(self) -> dict:
        """
        ì½”ë“œë² ì´ìŠ¤ ì „ì²´ ë¶„ì„ (Sequential Thinking Phase 1)
        """
        print("ğŸ° Trinity Score ë¶„ì„ ì‹œì‘...")

        # Phase 1.1: íŒŒì¼ ìˆ˜ì§‘
        python_files = self._collect_python_files()
        print(f"ğŸ“ ë¶„ì„ ëŒ€ìƒ íŒŒì¼: {len(python_files)}ê°œ")

        # Phase 1.2: ê° ê¸°ë‘¥ë³„ ë¶„ì„
        self._analyze_truth(python_files)  # çœ - ê¸°ìˆ ì  ì •í™•ì„±
        self._analyze_goodness(python_files)  # å–„ - ì•ˆì „ì„±ê³¼ ì‹ ë¢°ì„±
        self._analyze_beauty(python_files)  # ç¾ - êµ¬ì¡°ì  ìš°ì•„í•¨
        self._analyze_serenity(python_files)  # å­ - í‰ì˜¨í•¨
        self._analyze_eternity(python_files)  # æ°¸ - ì§€ì†ê°€ëŠ¥ì„±

        # Phase 1.3: ì¢…í•© ì ìˆ˜ ê³„ì‚°
        self._calculate_overall_score()

        return self._get_results()

    def _collect_python_files(self) -> list[Path]:
        """Python íŒŒì¼ ìˆ˜ì§‘"""
        python_files = []
        exclude_dirs = {".git", "__pycache__", ".venv", "node_modules", "dist", "build"}

        for root, dirs, filenames in os.walk(self.project_root):
            # ì œì™¸ ë””ë ‰í† ë¦¬ í•„í„°ë§
            dirs[:] = [d for d in dirs if d not in exclude_dirs]

            python_files.extend(Path(root) / filename for filename in filenames if filename.endswith(".py"))

        return python_files

    def _analyze_truth(self, files: list[Path]) -> None:
        """
        çœ (Truth) - ê¸°ìˆ ì  ì •í™•ì„± ë¶„ì„
        íƒ€ì… íŒíŠ¸, MyPy í˜¸í™˜ì„±, ê¸°ìˆ ì  ì •í™•ì„± í‰ê°€
        """
        total_functions = 0
        typed_functions = 0
        mypy_errors = 0

        for file_path in files[:50]:  # ìƒ˜í”Œë§ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
            try:
                content = Path(file_path).read_text(encoding="utf-8")

                tree = ast.parse(content)

                # í•¨ìˆ˜ ìˆ˜ì§‘
                functions = [node for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
                total_functions += len(functions)
                typed_functions += len([fn for fn in functions if fn.returns is not None])

            except Exception:
                self.results["truth"]["details"].append(f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {file_path.name}")
                continue

        # íƒ€ì… ì»¤ë²„ë¦¬ì§€ ê³„ì‚°
        type_coverage = (typed_functions / total_functions * 100) if total_functions > 0 else 0

        # MyPy ì˜¤ë¥˜ í™•ì¸ (ê°„ë‹¨í•œ ê²€ì¦)
        try:
            import subprocess

            result = subprocess.run(
                [
                    sys.executable,
                    "-m",
                    "mypy",
                    str(self.project_root / "packages"),
                    "--no-error-summary",
                ],
                capture_output=True,
                text=True,
                timeout=10,
                check=False,
            )
            mypy_errors = len([line for line in result.stdout.split("\n") if line.strip() and "error:" in line])
        except Exception:
            mypy_errors = 0  # MyPyê°€ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì²˜ë¦¬

        # ì ìˆ˜ ê³„ì‚°
        coverage_score = min(100, type_coverage * 1.5)  # 70% ì»¤ë²„ë¦¬ì§€ = 100ì 
        mypy_score = max(0, 100 - mypy_errors * 10)  # ì˜¤ë¥˜ë‹¹ 10ì  ê°ì 
        truth_score = (coverage_score + mypy_score) / 2

        self.results["truth"]["score"] = truth_score
        self.results["truth"]["details"] = [
            f"íƒ€ì… ì»¤ë²„ë¦¬ì§€: {type_coverage:.1f}%",
            f"MyPy ì˜¤ë¥˜: {mypy_errors}ê°œ",
            f"ì´ í•¨ìˆ˜ ìˆ˜: {total_functions}",
            f"íƒ€ì… íŒíŠ¸ í•¨ìˆ˜: {typed_functions}",
        ]

    def _analyze_goodness(self, files: list[Path]) -> None:
        """
        å–„ (Goodness) - ì•ˆì „ì„±ê³¼ ì‹ ë¢°ì„± ë¶„ì„
        ì—ëŸ¬ í•¸ë“¤ë§, í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€, ë³´ì•ˆ ê²€ì¦
        """
        error_handling_score = 0
        test_coverage_score = 0

        # ì—ëŸ¬ í•¸ë“¤ë§ ë¶„ì„
        total_files = len(files)
        files_with_error_handling = 0

        for file_path in files[:30]:  # ìƒ˜í”Œë§
            try:
                content = Path(file_path).read_text(encoding="utf-8")

                if "try:" in content and "except" in content:
                    files_with_error_handling += 1

            except Exception:
                continue

        error_handling_score = (files_with_error_handling / total_files * 100) if total_files > 0 else 0

        # í…ŒìŠ¤íŠ¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
        test_files = []
        for _root, _dirs, filenames in os.walk(self.project_root):
            test_files.extend(
                filename for filename in filenames if filename.startswith("test_") and filename.endswith(".py")
            )

        test_ratio = len(test_files) / max(1, total_files // 10)  # íŒŒì¼ë‹¹ 0.1ê°œ í…ŒìŠ¤íŠ¸ íŒŒì¼ ê¸°ì¤€
        test_coverage_score = min(100, test_ratio * 100)

        # ì¢…í•© ì ìˆ˜
        goodness_score = (error_handling_score + test_coverage_score) / 2

        self.results["goodness"]["score"] = goodness_score
        self.results["goodness"]["details"] = [
            f"ì—ëŸ¬ í•¸ë“¤ë§ ì ìš©ë¥ : {error_handling_score:.1f}%",
            f"í…ŒìŠ¤íŠ¸ íŒŒì¼ ìˆ˜: {len(test_files)}ê°œ",
            f"í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€: {test_coverage_score:.1f}%",
        ]

    def _analyze_beauty(self, files: list[Path]) -> None:
        """
        ç¾ (Beauty) - êµ¬ì¡°ì  ìš°ì•„í•¨ ë¶„ì„
        ì½”ë“œ ë³µì¡ë„, ëª¨ë“ˆí™”, ì¼ê´€ì„± í‰ê°€
        """
        complexity_score = 100
        modularity_score = 0

        # ë³µì¡ë„ ë¶„ì„
        high_complexity_files = 0
        total_analyzed = 0

        for file_path in files[:20]:  # ìƒ˜í”Œë§
            try:
                content = Path(file_path).read_text(encoding="utf-8")

                lines = content.split("\n")
                # ê°„ë‹¨í•œ ë³µì¡ë„ ì¸¡ì •: íŒŒì¼ ê¸¸ì´ ê¸°ë°˜
                if len(lines) > 300:  # 300ì¤„ ì´ìƒ = ë³µì¡
                    high_complexity_files += 1
                total_analyzed += 1

            except Exception:
                continue

        if total_analyzed > 0:
            complexity_score = max(0, 100 - (high_complexity_files / total_analyzed) * 50)

        # ëª¨ë“ˆí™” ë¶„ì„
        packages_dir = self.project_root / "packages"
        if packages_dir.exists():
            subpackages = [d for d in packages_dir.iterdir() if d.is_dir()]
            modularity_score = min(100, len(subpackages) * 25)  # íŒ¨í‚¤ì§€ë‹¹ 25ì 

        # ì¢…í•© ì ìˆ˜
        beauty_score = (complexity_score + modularity_score) / 2

        self.results["beauty"]["score"] = beauty_score
        self.results["beauty"]["details"] = [
            f"ì½”ë“œ ë³µì¡ë„ ì ìˆ˜: {complexity_score:.1f}",
            f"ëª¨ë“ˆí™” ì ìˆ˜: {modularity_score:.1f}",
            f"ê³ ë³µì¡ë„ íŒŒì¼: {high_complexity_files}ê°œ",
        ]

    def _analyze_serenity(self, files: list[Path]) -> None:
        """
        å­ (Serenity) - í‰ì˜¨í•¨ ë¶„ì„
        ìë™í™” ìˆ˜ì¤€, ìœ ì§€ë³´ìˆ˜ì„±, ê°œë°œì ê²½í—˜
        """
        automation_score = 0
        maintenance_score = 0

        # ìë™í™” ë„êµ¬ í™•ì¸
        automation_tools = ["pre-commit", "black", "isort", "mypy", "pytest"]
        found_tools = 0

        if (self.project_root / ".pre-commit-config.yaml").exists():
            found_tools += 1
        if (self.project_root / "pyproject.toml").exists():
            found_tools += 1

        automation_score = (found_tools / len(automation_tools)) * 100

        # ìœ ì§€ë³´ìˆ˜ì„± ë¶„ì„ (ë¬¸ì„œí™”, README ë“±)
        docs_score = 0
        if (self.project_root / "README.md").exists():
            docs_score += 25
        if (self.project_root / "docs").exists():
            docs_score += 25
        if any(f.suffix == ".md" for f in self.project_root.iterdir()):
            docs_score += 25

        maintenance_score = docs_score

        # ì¢…í•© ì ìˆ˜
        serenity_score = (automation_score + maintenance_score) / 2

        self.results["serenity"]["score"] = serenity_score
        self.results["serenity"]["details"] = [
            f"ìë™í™” ë„êµ¬ ì ìˆ˜: {automation_score:.1f}",
            f"ìœ ì§€ë³´ìˆ˜ì„± ì ìˆ˜: {maintenance_score:.1f}",
            f"ë¬¸ì„œí™” ìƒíƒœ: {'ì–‘í˜¸' if docs_score >= 50 else 'ê°œì„  í•„ìš”'}",
        ]

    def _analyze_eternity(self, files: list[Path]) -> None:
        """
        æ°¸ (Eternity) - ì§€ì†ê°€ëŠ¥ì„± ë¶„ì„
        ë²„ì „ ê´€ë¦¬, í™•ì¥ì„±, ë¯¸ë˜ ëŒ€ë¹„
        """
        version_control_score = 0
        scalability_score = 0

        # ë²„ì „ ê´€ë¦¬ ì ìˆ˜
        if (self.project_root / ".git").exists():
            version_control_score += 50
        if (self.project_root / "pyproject.toml").exists():
            version_control_score += 25
        if any(f.name.endswith(".lock") for f in self.project_root.iterdir()):
            version_control_score += 25

        # í™•ì¥ì„± ë¶„ì„ (ëª¨ë“ˆ êµ¬ì¡°, ì¸í„°í˜ì´ìŠ¤ ë“±)
        interfaces_found = 0
        for file_path in files[:30]:
            try:
                content = Path(file_path).read_text(encoding="utf-8")
                if "class" in content and "def" in content:
                    interfaces_found += 1
            except Exception:
                continue

        scalability_score = min(100, interfaces_found * 10)  # ì¸í„°í˜ì´ìŠ¤ë‹¹ 10ì 

        # ì¢…í•© ì ìˆ˜
        eternity_score = (version_control_score + scalability_score) / 2

        self.results["eternity"]["score"] = eternity_score
        self.results["eternity"]["details"] = [
            f"ë²„ì „ ê´€ë¦¬ ì ìˆ˜: {version_control_score:.1f}",
            f"í™•ì¥ì„± ì ìˆ˜: {scalability_score:.1f}",
            f"ì¸í„°í˜ì´ìŠ¤ ìˆ˜: {interfaces_found}ê°œ",
        ]

    def _calculate_overall_score(self) -> None:
        """ì¢…í•© Trinity Score ê³„ì‚°"""
        self.overall_score = sum(self.results[pillar]["score"] * weight for pillar, weight in TRINITY_WEIGHTS.items())

    def _get_results(self) -> dict:
        """ê²°ê³¼ ë°˜í™˜"""
        return {
            "timestamp": (Path(__file__).stat().st_mtime if Path(__file__).exists() else 0),
            "pillars": self.results,
            "overall_score": round(self.overall_score, 1),
            "grade": self._get_grade(),
            "requirements_met": self._check_requirements(),
        }

    def _get_grade(self) -> str:
        """ì ìˆ˜ì— ë”°ë¥¸ ë“±ê¸‰ íŒì •"""
        if self.overall_score >= 95:
            return "íƒì›” (Excellent)"
        if self.overall_score >= 90:
            return "ìš°ìˆ˜ (Great)"
        if self.overall_score >= 80:
            return "ì–‘í˜¸ (Good)"
        if self.overall_score >= 70:
            return "ë³´í†µ (Fair)"
        if self.overall_score >= 60:
            return "ë¯¸í¡ (Poor)"
        return "ê°œì„  í•„ìš” (Critical)"

    def _check_requirements(self) -> bool:
        """ìµœì†Œ ìš”êµ¬ì‚¬í•­ ì¶©ì¡± ì—¬ë¶€ í™•ì¸"""
        # ê°„ë‹¨í•œ ê²€ì¦ë§Œ ìˆ˜í–‰ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ê²€ì¦ í•„ìš”)
        return self.overall_score >= MIN_REQUIREMENTS["trinity_score"]


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ° AFO ì™•êµ­ Trinity Score ê²€ì¦")
    print("=" * 50)

    project_root = Path(__file__).parent.parent
    checker = TrinityScoreChecker(project_root)

    try:
        results = checker.analyze_codebase()

        print("\nğŸ“Š Trinity Score ê²°ê³¼:")
        print(f"ì¢…í•© ì ìˆ˜: {results['overall_score']:.1f}/100")
        print(f"ë“±ê¸‰: {results['grade']}")

        print("\nğŸ” ì„¸ë¶€ ì ìˆ˜:")
        for pillar, data in results["pillars"].items():
            pillar_names = {
                "truth": "çœ (Truth)",
                "goodness": "å–„ (Goodness)",
                "beauty": "ç¾ (Beauty)",
                "serenity": "å­ (Serenity)",
                "eternity": "æ°¸ (Eternity)",
            }
            print(f"  {pillar_names[pillar]}: {data['score']:.1f}")
            for detail in data["details"][:2]:  # ì£¼ìš” ì •ë³´ë§Œ í‘œì‹œ
                print(f"    â€¢ {detail}")

        # ìš”êµ¬ì‚¬í•­ ê²€ì¦
        if results["requirements_met"]:
            print(f"\nâœ… ìµœì†Œ ìš”êµ¬ì‚¬í•­ ì¶©ì¡± (Trinity Score {MIN_REQUIREMENTS['trinity_score']}ì  ì´ìƒ)")
            return 0
        print(f"\nâŒ ìµœì†Œ ìš”êµ¬ì‚¬í•­ ë¯¸ì¶©ì¡± (Trinity Score {MIN_REQUIREMENTS['trinity_score']}ì  í•„ìš”)")
        print("ì½”ë“œ í’ˆì§ˆ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return 1

    except Exception as e:
        print(f"âŒ Trinity Score ê²€ì¦ ì‹¤íŒ¨: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
