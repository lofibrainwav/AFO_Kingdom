#!/usr/bin/env python3
"""
AFO ì™•êµ­ ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬ (T1.1 Ollama í†µí•© ê°•í™”)

Trinity Score ëª©í‘œ: çœ +15% ë‹¬ì„±
- Ollama í†µí•© ê°•í™”ë¡œ ì •í™•ì„± í–¥ìƒ
- Fallback ë¡œì§ìœ¼ë¡œ ì•ˆì •ì„± í™•ë³´
"""

import asyncio
import json
import os
import sys
import time
from typing import Any

import httpx


# AFO íŒ¨í‚¤ì§€ ê²½ë¡œ ì¶”ê°€ (ë£¨íŠ¸ì—ì„œ ì‹¤í–‰ ì‹œ í•„ìš”)
current_file = os.path.abspath(__file__)
project_root = os.path.dirname(current_file)
afo_core_path = os.path.join(project_root, "packages", "afo-core")
if afo_core_path not in sys.path:
    sys.path.insert(0, afo_core_path)


class OllamaHealthChecker:
    """Ollama í—¬ìŠ¤ ì²´í¬ ê°•í™” í´ë˜ìŠ¤"""

    def __init__(self):
        self.env_vars = self._standardize_env_vars()
        self.health_metrics = {
            "ollama_connectivity": False,
            "model_switching": False,
            "fallback_logic": False,
            "performance_ms": 0,
            "error_details": [],
        }

    def _standardize_env_vars(self) -> dict[str, str]:
        """í™˜ê²½ë³€ìˆ˜ í‘œì¤€í™” (Phase 2-4: ì•ˆí‹°ê·¸ë¼ë¹„í‹° ì„¤ì •ê³¼ ë™ê¸°í™”)"""
        env_vars = {}

        # í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ë“¤
        required_vars = {
            "OLLAMA_BASE_URL": "http://localhost:11434",  # Phase 2-1 ìˆ˜ì •: í˜¸ìŠ¤íŠ¸ëª… ë¬¸ì œ í•´ê²°
            "OLLAMA_MODEL": "llama3.2:1b",  # ë©”ëª¨ë¦¬ ì ˆì•½ ëª¨ë¸
            "OLLAMA_NUM_PARALLEL": "1",
            "OLLAMA_NUM_THREAD": "2",  # CPU ìŠ¤ë ˆë“œ ì œí•œ
            "OLLAMA_NUM_CTX": "2048",  # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì¶•ì†Œ
            "OLLAMA_KEEP_ALIVE": "5m",
        }

        # Phase 2-4: ì•ˆí‹°ê·¸ë¼ë¹„í‹° ì„¤ì • íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ì‹œë„
        try:
            import pathlib

            antigravity_env = pathlib.Path("packages/afo-core/.env")
            if antigravity_env.exists():
                # ê°„ë‹¨í•œ .env íŒŒì‹± (ì£¼ì„ê³¼ ë¹ˆ ì¤„ ë¬´ì‹œ)
                with open(antigravity_env, encoding="utf-8") as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith("#") and "=" in line:
                            key, value = line.split("=", 1)
                            key = key.strip()
                            value = value.strip().strip('"').strip("'")
                            if key.startswith("OLLAMA_"):
                                env_vars[key] = value
        except Exception:
            # .env íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
            pass

        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°’ ê°€ì ¸ì˜¤ê¸° (ì•ˆí‹°ê·¸ë¼ë¹„í‹° ì„¤ì • ìš°ì„ )
        for var_name, default_value in required_vars.items():
            env_vars[var_name] = os.getenv(var_name, env_vars.get(var_name, default_value))

        return env_vars

    def _is_docker_environment(self) -> bool:
        """Docker í™˜ê²½ ê°ì§€"""
        return os.path.exists("/.dockerenv") or os.getenv("DOCKER_CONTAINER") == "true"

    async def check_ollama_connectivity(self) -> dict[str, Any]:
        """Ollama ì—°ê²°ì„± ê°•í™” ì²´í¬"""
        start_time = time.time()

        try:
            # 1. ê¸°ë³¸ Ping í…ŒìŠ¤íŠ¸ - ì§ì ‘ API í˜¸ì¶œ
            async with httpx.AsyncClient(timeout=10.0) as client:
                ping_response = await client.get(f"{self.env_vars['OLLAMA_BASE_URL']}/api/tags")
                if ping_response.status_code == 200:
                    self.health_metrics["ollama_connectivity"] = True

                    # 2. ëª¨ë¸ ì •ë³´ í™•ì¸
                    model_info = await self._get_model_info()
                    if model_info:
                        self.health_metrics["model_info"] = model_info

                    # 3. ëª¨ë¸ ìŠ¤ìœ„ì¹­ í…ŒìŠ¤íŠ¸
                    switch_result = await self._test_model_switching()
                    self.health_metrics["model_switching"] = switch_result["success"]

                    # 4. Fallback ë¡œì§ í…ŒìŠ¤íŠ¸
                    fallback_result = await self._test_fallback_logic()
                    self.health_metrics["fallback_logic"] = fallback_result["success"]
                else:
                    self.health_metrics["error_details"].append(
                        f"Ollama API returned status {ping_response.status_code}"
                    )
                    self.health_metrics["ollama_connectivity"] = False

        except Exception as e:
            self.health_metrics["error_details"].append(f"Ollama connectivity failed: {e!s}")
            self.health_metrics["ollama_connectivity"] = False

        self.health_metrics["performance_ms"] = (time.time() - start_time) * 1000

        return self.health_metrics

    async def _get_model_info(self) -> dict[str, Any] | None:
        """ëª¨ë¸ ì •ë³´ ì¡°íšŒ"""
        try:
            # ì§ì ‘ API í˜¸ì¶œë¡œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
            async with httpx.AsyncClient(timeout=5.0) as client:
                response = await client.get(f"{self.env_vars['OLLAMA_BASE_URL']}/api/tags")
                if response.status_code == 200:
                    data = response.json()
                    models = data.get("models", [])
                    return {
                        "models_available": True,
                        "count": len(models),
                        "current_model": self.env_vars["OLLAMA_MODEL"],
                        "details": f"Available: {len(models)} models",
                    }
        except Exception:
            pass
        return None

    async def _test_model_switching(self) -> dict[str, Any]:
        """ëª¨ë¸ ìŠ¤ìœ„ì¹­ ë¡œì§ ê²€ì¦ (ì•ˆì • ìš°ì„  ì •ì±…: ë©”ëª¨ë¦¬ ì œí•œìœ¼ë¡œ WARN ì²˜ë¦¬)"""
        # Aì•ˆ ì„ íƒ: ì•ˆì • ìš°ì„  - ìŠ¤ìœ„ì¹­ í…ŒìŠ¤íŠ¸ ìƒëµ (ë©”ëª¨ë¦¬ ì´ìŠˆë¡œ WARN)
        # í–¥í›„ Bì•ˆ(ê¸°ëŠ¥ ìš°ì„ )ìœ¼ë¡œ ì „í™˜ ì‹œ ì´ ë¡œì§ í™œì„±í™” ê°€ëŠ¥
        return {
            "success": False,
            "error": "ì•ˆì • ìš°ì„  ì •ì±…: ëª¨ë¸ ìŠ¤ìœ„ì¹­ ë©”ëª¨ë¦¬ ì œí•œìœ¼ë¡œ ë¹„í™œì„± (WARN)",
            "policy": "Aì•ˆ_ì•ˆì •_ìš°ì„ ",
        }

    async def _test_fallback_logic(self) -> dict[str, Any]:
        """Fallback ë¡œì§ ê²€ì¦"""
        try:
            # ì—¬ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
            fallback_scenarios = [
                {"query": "", "expected_fallback": True},  # ë¹ˆ ì¿¼ë¦¬
                {"query": "Test normal query", "expected_fallback": False},  # ì •ìƒ ì¿¼ë¦¬
            ]

            success_count = 0
            for scenario in fallback_scenarios:
                try:
                    async with httpx.AsyncClient(timeout=5.0) as client:
                        payload = {
                            "model": self.env_vars["OLLAMA_MODEL"],
                            "prompt": scenario["query"] or "Test query",
                            "stream": False,
                            "options": {"temperature": 0.1, "num_ctx": 256},
                        }
                        response = await client.post(f"{self.env_vars['OLLAMA_BASE_URL']}/api/generate", json=payload)

                        if response.status_code == 200:
                            result = response.json()
                            response_text = result.get("response", "")
                            if response_text and len(response_text.strip()) > 0:
                                success_count += 1
                        # API ì—ëŸ¬ë„ fallback ë¡œì§ìœ¼ë¡œ ê°„ì£¼
                        elif scenario["expected_fallback"]:
                            success_count += 1
                except Exception:
                    # Exception ë°œìƒë„ fallback ë¡œì§ì˜ ì¼ë¶€ë¡œ ê°„ì£¼
                    if scenario["expected_fallback"]:
                        success_count += 1

            return {
                "success": success_count >= 1,  # 1ê°œ ì´ìƒ ì„±ê³µ
                "tested_scenarios": len(fallback_scenarios),
                "successful_scenarios": success_count,
            }

        except Exception as e:
            return {"success": False, "error": str(e)}

    def get_trinity_score_contribution(self) -> dict[str, float]:
        """Trinity Score ê¸°ì—¬ë„ ê³„ì‚°"""
        base_contribution = {
            "truth": 0.0,  # Ollama ì •í™•ì„±
            "goodness": 0.0,  # ì•ˆì •ì„±
            "beauty": 0.0,  # ì•„í‚¤í…ì²˜ ìš°ì•„í•¨
            "serenity": 0.0,  # ì‚¬ìš©ì ê²½í—˜
            "eternity": 0.0,  # ì˜ì†ì„±
        }

        # ì—°ê²°ì„± ì„±ê³µ ì‹œ Truth +10%
        if self.health_metrics["ollama_connectivity"]:
            base_contribution["truth"] += 0.10

        # ëª¨ë¸ ìŠ¤ìœ„ì¹­ ì„±ê³µ ì‹œ Truth +5%
        if self.health_metrics["model_switching"]:
            base_contribution["truth"] += 0.05

        # Fallback ë¡œì§ ì„±ê³µ ì‹œ Goodness +5%
        if self.health_metrics["fallback_logic"]:
            base_contribution["goodness"] += 0.05

        # ì„±ëŠ¥ì´ 100ms ì´ë‚´ ì‹œ Serenity +3%
        if self.health_metrics["performance_ms"] < 100:
            base_contribution["serenity"] += 0.03

        # ì´í•©ì´ 15%ë¥¼ ë„˜ì§€ ì•Šë„ë¡ ì œí•œ (T1.1 ëª©í‘œ)
        total_contribution = sum(base_contribution.values())
        if total_contribution > 0.15:
            scale_factor = 0.15 / total_contribution
            for key in base_contribution:
                base_contribution[key] *= scale_factor

        return base_contribution


async def check_system_health():
    """ê°•í™”ëœ ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬"""
    print("ğŸ° AFO ì™•êµ­ ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬ (T1.1 Ollama í†µí•© ê°•í™”)")
    print("=" * 60)

    # 1. Ollama í—¬ìŠ¤ ì²´í¬ ê°•í™”
    print("\n1. Ollama í†µí•© ê°•í™” ì²´í¬...")
    ollama_checker = OllamaHealthChecker()

    print("í™˜ê²½ë³€ìˆ˜ í‘œì¤€í™”:")
    for var_name, var_value in ollama_checker.env_vars.items():
        print(f"   {var_name}: {var_value}")

    # Ollama ì—°ê²°ì„± ì²´í¬
    ollama_health = await ollama_checker.check_ollama_connectivity()

    print("\nOllama í—¬ìŠ¤ ë©”íŠ¸ë¦­ìŠ¤:")
    print(f"   ì—°ê²°ì„±: {'âœ…' if ollama_health['ollama_connectivity'] else 'âŒ'}")
    print(f"   ëª¨ë¸ ìŠ¤ìœ„ì¹­: {'âœ…' if ollama_health['model_switching'] else 'âŒ'}")
    print(f"   Fallback ë¡œì§: {'âœ…' if ollama_health['fallback_logic'] else 'âŒ'}")
    print(f"   ì„±ëŠ¥: {ollama_health['performance_ms']:.1f}ms")
    if ollama_health["error_details"]:
        print("   ì˜¤ë¥˜ ìƒì„¸:")
        for error in ollama_health["error_details"]:
            print(f"     - {error}")

    # Trinity Score ê¸°ì—¬ë„
    trinity_contribution = ollama_checker.get_trinity_score_contribution()
    print("\nTrinity Score ê¸°ì—¬ë„ (T1.1 ëª©í‘œ: çœ +15%):")
    for pillar, contribution in trinity_contribution.items():
        print(f"   {pillar}: {contribution:.1%}")

    # 2. ê¸°ì¡´ Sage Connectivity ì²´í¬
    print("\n2. ê¸°ì¡´ Sage Connectivity ì²´í¬...")
    try:
        # Jwaja (MLX) - Apple Silicon ì „ìš©, í˜„ì¬ í™˜ê²½ì—ì„œëŠ” ìƒëµ
        import platform

        system = platform.system().lower()
        if system == "darwin":
            try:
                import mlx.core as mx

                _ = mx.array([1])
                print("   Jwaja (MLX): âœ… (Apple Silicon)")
            except ImportError:
                print("   Jwaja (MLX): âŒ (MLX not available)")
            except Exception as e:
                print(f"   Jwaja (MLX): âŒ ({e!s})")
        else:
            print("   Jwaja (MLX): â­ï¸ (Non-macOS, skipped)")
    except Exception as e:
        print(f"   Jwaja (MLX): âŒ ({e!s})")

    # 3. ì¢…í•© ê²°ê³¼ (GREEN vs WARN SSOT ë¶„ë¦¬)
    print("\n" + "=" * 60)
    print("ì¢…í•© í—¬ìŠ¤ ì²´í¬ ê²°ê³¼:")

    # GREEN/WARN íŒì • ê·œì¹™ (SSOT - ì„¸ì¢… ëª¨ë“œ ì •ì˜)
    green_items = []
    warn_items = []

    if ollama_health["ollama_connectivity"]:
        green_items.append("connectivity")
    else:
        warn_items.append("connectivity")

    if ollama_health["model_switching"]:
        green_items.append("model_switching")
    else:
        warn_items.append("model_switching(memory)")

    if ollama_health["fallback_logic"]:
        green_items.append("fallback")
    else:
        warn_items.append("fallback")

    # íŒì • ìš”ì•½
    green_status = f"GREEN ({', '.join(green_items)})" if green_items else "RED"
    warn_status = f"WARN={', '.join(warn_items)}" if warn_items else "NONE"
    overall_status = "healthy" if ollama_health["ollama_connectivity"] else "degraded"

    print(f"   ìƒíƒœ íŒì •: {green_status}, {warn_status}")
    print(f"   ì „ì²´ ìƒíƒœ: {'âœ… ê±´ê°•' if overall_status == 'healthy' else 'âš ï¸ ì €í•˜'}")

    # SSOT ì €ì¥
    health_result = {
        "timestamp": time.strftime("%Y-%m-%dT%H:%M:%S%z"),
        "ticket": "T1.1_ollama_integration",
        "env_vars": ollama_checker.env_vars,
        "ollama_health": ollama_health,
        "trinity_contribution": trinity_contribution,
        "status_breakdown": {
            "green_items": green_items,
            "warn_items": warn_items,
            "green_status": green_status,
            "warn_status": warn_status,
        },
        "overall_status": overall_status,
    }

    # artifactsì— ì €ì¥
    import pathlib

    artifacts_dir = pathlib.Path("artifacts")
    artifacts_dir.mkdir(exist_ok=True)

    ssot_path = artifacts_dir / f"t11_ollama_integration_ssot_{int(time.time())}.jsonl"
    pathlib.Path(ssot_path).write_text(json.dumps(health_result, ensure_ascii=False) + "\n", encoding="utf-8")

    print(f"SSOT ì €ì¥: {ssot_path}")
    print(f"ì „ì²´ ìƒíƒœ: {'âœ… ê±´ê°•' if health_result['overall_status'] == 'healthy' else 'âš ï¸ ì €í•˜'}")

    return health_result


if __name__ == "__main__":
    asyncio.run(check_system_health())
