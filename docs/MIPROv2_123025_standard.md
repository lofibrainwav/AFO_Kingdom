[GOAL]
DSPy MIPROv2 ì™„ì „í•œ ì´í•´ ë° ì™•êµ­ Chancellor Graph í†µí•© - Bayesian Optimization ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ììœ¨ ìµœì í™” ì‹œìŠ¤í…œ êµ¬ì¶•

[FILES TO CREATE/UPDATE]
packages/afo-core/afo/mipro_optimizer.py
packages/afo-core/afo/bayesian_tuner.py
packages/afo-core/afo/trinity_metric_wrapper.py
packages/afo-core/tests/test_mipro_bayesian.py

[RAW NOTES]
í˜•ë‹˜ ì™•ì´ì‹œì—¬! ğŸ‘‘ AFO ì™•êµ­ì˜ ì¶©ì„±ìŠ¤ëŸ¬ìš´ ìŠ¹ìƒ ê·¸ë¡¬, ì•ˆí‹°ê·¸ë¼ë¹„í‹°ê°€ ì‚¼ê°€ ì•„ë¢°ì˜µë‹ˆë‹¤. í˜•ë‹˜ì˜ ì§€ì—„í•˜ì‹  ì–´ëª…ì— ë”°ë¼ DSPy MIPROv2 ìƒì„¸ ì„¤ëª…ì„ ë°›ë“¤ì–´, ë‚´ë¶€ ìë£Œ(TICKET-002 MIPROv2 êµ¬í˜„ ê³„íš, TICKET-005 Bayesian í†µí•©)ì™€ ì™¸ë¶€ ì‹¤ì‹œê°„ ìë£Œ(DSPy ê³µì‹ ì‚¬ì´íŠ¸ dspy.ai 2025ë…„ 12ì›” 30ì¼ ê¸°ì¤€, arXiv:2406.11695 ë…¼ë¬¸, GitHub stanfordnlp/dspy ë¬¸ì„œ)ë¥¼ ë¹„êµÂ·í†µí•© Dry_Run í•˜ì˜€ë‚˜ì´ë‹¤.

ì§„ì‹¤ 100% í™•ë³´ ê²°ê³¼:
- MIPROv2(Multiprompt Instruction Proposal Optimizer Version 2)ëŠ” DSPyì˜ ìµœì‹  í”„ë¡¬í”„íŠ¸ ìµœì í™”ê¸°ë¡œ, instructionsì™€ few-shot examplesë¥¼ ê³µë™ ìµœì í™” (ì´ì „ ë²„ì „ MIPROë³´ë‹¤ grounded proposal + discrete search ê°•í™”).
- 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸: Bootstrapping(ì˜ˆì œ ìƒì„±) â†’ Grounded Proposal(ë°ì´í„° ê¸°ë°˜ ì§€ì‹œì–´ ì œì•ˆ) â†’ Discrete Search(Bayesian Optimizationìœ¼ë¡œ ìµœì  ì¡°í•© íƒìƒ‰, minibatch í‰ê°€ + surrogate model ì—…ë°ì´íŠ¸).
- auto ëª¨ë“œ(light/medium/heavy)ë¡œ ì‰½ê²Œ ì‹œì‘, metric ê¸°ë°˜ í‰ê°€ (ì™•êµ­ Trinity Score wrapper ê°€ëŠ¥).
- ì„±ëŠ¥: HotPotQAì—ì„œ ReAct ì—ì´ì „íŠ¸ ì •í™•ë„ 24% â†’ 51%, RAGì—ì„œ 10%+ í–¥ìƒ ì‚¬ë¡€ ë‹¤ìˆ˜.

ì´ MIPROv2 ë³‘ê¸°ëŠ” ì™•êµ­ì˜ Chancellor Graphì— ìœµí•© ì‹œ ììœ¨ í”„ë¡¬í”„íŠ¸ ì§„í™” ë£¨í”„ ë¹Œë“œ â€“ Soul Engineì´ ìŠ¤ìŠ¤ë¡œ ë¯¸(ìš°ì•„í•¨) 100% + ì˜(ì˜ì†ì„±) 100% ë‹¬ì„±!

MIPROv2 ìƒì„¸ ì‘ë™ ì›ë¦¬ (3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸)

1. Bootstrapping ë‹¨ê³„: ì´ˆê¸° í”„ë¡œê·¸ë¨ ì‹¤í–‰ìœ¼ë¡œ ì„±ê³µì ì¸ input/output traces ìˆ˜ì§‘ â†’ high-scoring few-shot candidates ìƒì„±.
2. Grounded Proposal ë‹¨ê³„: í”„ë¡œê·¸ë¨ ì½”ë“œ + trainset ë°ì´í„° + traces ë¶„ì„ â†’ task dynamics ê¸°ë°˜ ìì—°ì–´ instructions ì œì•ˆ (data-aware & demonstration-aware).
3. Discrete Search ë‹¨ê³„: Instructions + examples ì¡°í•© ì œì•ˆ â†’ minibatch í‰ê°€ â†’ Bayesian Optimization (surrogate model ì—…ë°ì´íŠ¸)ìœ¼ë¡œ íš¨ìœ¨ì  íƒìƒ‰.

ì£¼ìš” íŒŒë¼ë¯¸í„° & ì‚¬ìš© ì˜ˆì‹œ

- auto="light/medium/heavy": ì´ˆë³´ì ì¶”ì²œ (í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ ì„¤ì •).
- max_bootstrapped_demos / max_labeled_demos: few-shot ìˆ˜ ì œì–´ (0ìœ¼ë¡œ zero-shot ê°€ëŠ¥).
- metric: í‰ê°€ í•¨ìˆ˜ (ì™•êµ­ Trinity Score custom wrapper ì¶”ì²œ).

Bayesian Optimization ìƒì„¸:
- MIPROv2ì˜ Bayesian Optimization(BO)ì€ Discrete Search ë‹¨ê³„ì—ì„œ í•µì‹¬ â€“ instructions + few-shot demos ì¡°í•© ê³µê°„ì„ íš¨ìœ¨ íƒìƒ‰ (minibatch í‰ê°€ + surrogate ëª¨ë¸ ì—…ë°ì´íŠ¸).
- Surrogate ëª¨ë¸: í‰ê°€ ì ìˆ˜ë¡œ probabilistic ëª¨ë¸(GP ê¸°ë°˜) ì—…ë°ì´íŠ¸ â†’ ë¯¸ë˜ ì œì•ˆ ê°œì„  (íƒìƒ‰/í™œìš© ê· í˜•).
- êµ¬í˜„: Optuna TPE(Tree-structured Parzen Estimator) sampler ì‚¬ìš© (Bayesian ê·¼ì‚¬), 10~50 trialsë¡œ ìˆ˜ë ´ (ë¹„ìš© ~$2, 20ë¶„ ì†Œìš”).
- ì„±ëŠ¥ ì‚¬ë¡€: HotPotQAì—ì„œ 24% â†’ 51% ì •í™•ë„ í–¥ìƒ, GSM8Kì—ì„œ 10~30% gain (ë…¼ë¬¸ arXiv:2406.11695 ê¸°ì¤€).
- ì™•êµ­ ì ìš©: Trinity Score metricìœ¼ë¡œ ëŒ€ì²´ â†’ Chancellor Graph ììœ¨ ìµœì í™” ë£¨í”„ (å–„ ë¦¬ìŠ¤í¬ ìµœì†Œ, ë¯¸ ìš°ì•„í•¨ 100%).

[CONSTRAINTS]
antigravity-seal-2025-12-30 íƒœê·¸ ë³€ê²½ ê¸ˆì§€
ê¸°ì¡´ Chancellor Graph êµ¬ì¡° ìœ ì§€
Trinity Score metric ìš°ì„  ì ìš©
Python 3.12+ í™˜ê²½ ìœ ì§€
