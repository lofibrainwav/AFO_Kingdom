#!/usr/bin/env python3
"""
Qwen3-VL MLX PoC êµ¬í˜„ (Apple Silicon M4 ìµœì í™”)

ì´ ëª¨ë“ˆì€ Qwen3-VL ë¹„ì „-ì–¸ì–´ ëª¨ë¸ì„ MLX í”„ë ˆì„ì›Œí¬ë¡œ ì‹¤í–‰í•˜ëŠ” PoCì…ë‹ˆë‹¤.
ì´ë¯¸ì§€ ë¶„ì„ + í…ìŠ¤íŠ¸ ìƒì„± ì²´ì¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python qwen3_vl_poc.py --image path/to/image.png --prompt "ì´ë¯¸ì§€ ë¶„ì„í•´ì¤˜"
"""

import argparse
import logging
import os
import time

# MLX-VLM imports
try:
    from mlx_lm import generate as llm_generate
    from mlx_lm import load
    from mlx_vlm import generate as vlm_generate

    MLX_VLM_AVAILABLE = True
except ImportError:
    print("mlx-vlm not available. Please install: pip install mlx-vlm")
    MLX_VLM_AVAILABLE = False

# ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
import psutil

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class Qwen3VLMLXPOC:
    """
    Qwen3-VL MLX PoC í´ë˜ìŠ¤

    Apple Silicon M4ì—ì„œ Qwen3-VLì„ MLXë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """

    def __init__(self, model_name: str = "mlx-community/Qwen3-VL-8B-Instruct-4bit"):
        """
        PoC ì´ˆê¸°í™”

        Args:
            model_name: ì‚¬ìš©í•  Qwen3-VL ëª¨ë¸ ì´ë¦„
        """
        self.model_name = model_name
        self.model = None
        self.tokenizer = None
        self.llm_model = None
        self.llm_tokenizer = None
        self.initialized = False

        logger.info("Qwen3-VL MLX PoC initialized with model: %s", model_name)

    def check_memory(self) -> dict:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸"""
        mem = psutil.virtual_memory()
        return {
            "total_gb": mem.total / (1024**3),
            "used_gb": mem.used / (1024**3),
            "available_gb": mem.available / (1024**3),
            "percentage": mem.percent,
        }

    def initialize_models(self) -> bool:
        """
        Qwen3-VLê³¼ Llama ëª¨ë¸ ì´ˆê¸°í™”

        Returns:
            ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
        """
        if not MLX_VLM_AVAILABLE:
            logger.error("mlx-vlm not available")
            return False

        try:
            # ë©”ëª¨ë¦¬ ì²´í¬ (ì´ˆê¸°í™” ì „)
            mem_before = self.check_memory()
            logger.info(
                f"Memory before initialization: {mem_before['used_gb']:.1f}GB used"
            )

            # Qwen3-VLì€ mlx_vlm.generate()ë¡œ ì§ì ‘ ì‚¬ìš©í•˜ë¯€ë¡œ ë³„ë„ ë¡œë“œ ë¶ˆí•„ìš”
            logger.info("Qwen3-VL ready for generation (mlx_vlm.generate)")

            # Llama 3.1 ëª¨ë¸ ë¡œë“œ (ì²´ì¸ìš©)
            llama_model = "mlx-community/Meta-Llama-3.1-8B-Instruct-4bit"
            logger.info("Loading Llama model: %s", llama_model)
            self.llm_model, self.llm_tokenizer = load(llama_model)

            # ë©”ëª¨ë¦¬ ì²´í¬ (ì´ˆê¸°í™” í›„)
            mem_after = self.check_memory()
            logger.info(
                f"Memory after initialization: {mem_after['used_gb']:.1f}GB used"
            )
            logger.info(
                f"Memory delta: {mem_after['used_gb'] - mem_before['used_gb']:.1f}GB"
            )

            self.initialized = True
            return True

        except Exception as e:
            logger.error("Model initialization failed: %s", e)
            return False

    def analyze_image(
        self, image_paths: list[str], prompt: str, max_tokens: int = 512
    ) -> str | None:
        """
        ì´ë¯¸ì§€ ë¶„ì„ ìˆ˜í–‰

        Args:
            image_paths: ë¶„ì„í•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œë“¤
            prompt: ë¶„ì„ í”„ë¡¬í”„íŠ¸
            max_tokens: ìµœëŒ€ ìƒì„± í† í° ìˆ˜

        Returns:
            ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸
        """
        if not self.initialized:
            logger.error("Models not initialized")
            return None

        if not MLX_VLM_AVAILABLE:
            return "mlx-vlm not available"

        try:
            # ë©”ëª¨ë¦¬ ì²´í¬
            mem_before = self.check_memory()
            logger.info(f"Memory before image analysis: {mem_before['used_gb']:.1f}GB")

            # ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ í™•ì¸
            for img_path in image_paths:
                if not os.path.exists(img_path):
                    logger.error("Image file not found: %s", img_path)
                    return f"Image file not found: {img_path}"

            # Qwen3-VLë¡œ ì´ë¯¸ì§€ ë¶„ì„
            start_time = time.time()
            logger.info(f"Analyzing {len(image_paths)} image(s) with Qwen3-VL...")

            result = vlm_generate(
                model=self.model_name,
                image=image_paths,
                prompt=prompt,
                max_tokens=max_tokens,
                temperature=0.1,  # ë‚®ì€ temperatureë¡œ ì •í™•í•œ ë¶„ì„
            )

            analysis_time = time.time() - start_time
            logger.info(f"Image analysis completed in {analysis_time:.2f}s")

            # ë©”ëª¨ë¦¬ ì²´í¬
            mem_after = self.check_memory()
            logger.info(f"Memory after analysis: {mem_after['used_gb']:.1f}GB")

            return result

        except Exception as e:
            logger.error("Image analysis failed: %s", e)
            return f"Analysis failed: {e!s}"

    def generate_followup(
        self, visual_analysis: str, followup_prompt: str, max_tokens: int = 512
    ) -> str | None:
        """
        ì‹œê° ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í›„ì† í…ìŠ¤íŠ¸ ìƒì„± (Llama ì²´ì¸)

        Args:
            visual_analysis: Qwen3-VLì˜ ì‹œê° ë¶„ì„ ê²°ê³¼
            followup_prompt: í›„ì† í”„ë¡¬í”„íŠ¸
            max_tokens: ìµœëŒ€ ìƒì„± í† í° ìˆ˜

        Returns:
            í›„ì† ìƒì„± ê²°ê³¼
        """
        if not self.initialized or not self.llm_model or not self.llm_tokenizer:
            logger.error("Llama model not initialized")
            return None

        try:
            # ì²´ì¸ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            chain_prompt = f"""ì‹œê° ë¶„ì„ ê²°ê³¼:
{visual_analysis}

{followup_prompt}

ë‹µë³€:"""

            start_time = time.time()
            logger.info("Generating followup with Llama...")

            result = llm_generate(
                self.llm_model,
                self.llm_tokenizer,
                prompt=chain_prompt,
                max_tokens=max_tokens,
                temperature=0.7,
            )

            generation_time = time.time() - start_time
            logger.info(f"Followup generation completed in {generation_time:.2f}s")

            return result

        except Exception as e:
            logger.error("Followup generation failed: %s", e)
            return f"Followup failed: {e!s}"

    def run_visual_debugging_chain(self, image_paths: list[str]) -> dict | None:
        """
        ì™„ì „í•œ ë¹„ì£¼ì–¼ ë””ë²„ê¹… ì²´ì¸ ì‹¤í–‰

        Args:
            image_paths: ë¶„ì„í•  ì´ë¯¸ì§€ë“¤

        Returns:
            ì²´ì¸ ì‹¤í–‰ ê²°ê³¼
        """
        # 1ë‹¨ê³„: ì´ë¯¸ì§€ ë¶„ì„ (Qwen3-VL)
        analysis_prompt = """ì´ ì´ë¯¸ì§€(ë“¤)ì„ ì² ì €íˆ ë¶„ì„í•´ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì¤˜:
1. UI/ëŒ€ì‹œë³´ë“œ êµ¬ì„± ìš”ì†Œ (ë²„íŠ¼, ì°¨íŠ¸, í…ìŠ¤íŠ¸ ë“±)
2. ë°ì´í„° ê°’ê³¼ ë©”íŠ¸ë¦­ (ìˆ«ì, í¼ì„¼íŠ¸, ìƒíƒœ ë“±)
3. ì ì¬ì  ë¬¸ì œë‚˜ ì—ëŸ¬ ì§•í›„
4. ì „ë°˜ì ì¸ ì‹œìŠ¤í…œ ìƒíƒœ

í•œêµ­ì–´ë¡œ ìì„¸íˆ ì„¤ëª…í•´ì¤˜."""

        visual_result = self.analyze_image(image_paths, analysis_prompt)
        if not visual_result:
            return {"error": "Image analysis failed"}

        # 2ë‹¨ê³„: ì²´ì¸ ë¶„ì„ (Llama)
        followup_prompt = """ìœ„ ì‹œê° ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ:

1. ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœ í‰ê°€ (EXCELLENT/GOOD/FAIR/POOR)
2. ë°œê²¬ëœ ë¬¸ì œì ê³¼ ê°œì„  ì œì•ˆ
3. ì¶”ê°€ ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•œ ë¶€ë¶„
4. Trinity Score (çœå–„ç¾å­æ°¸) ê¸°ë°˜ ì¢…í•© í‰ê°€

í˜•ë‹˜ì—ê²Œ ë³´ê³ í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì¤˜."""

        chain_result = self.generate_followup(visual_result, followup_prompt)
        if not chain_result:
            return {"error": "Chain analysis failed", "visual_analysis": visual_result}

        return {
            "visual_analysis": visual_result,
            "chain_analysis": chain_result,
            "timestamp": time.time(),
            "model": self.model_name,
            "images_processed": len(image_paths),
        }


def main():
    """ë©”ì¸ í•¨ìˆ˜ - CLI ì¸í„°í˜ì´ìŠ¤"""
    parser = argparse.ArgumentParser(description="Qwen3-VL MLX PoC")
    parser.add_argument(
        "--images", nargs="+", required=True, help="Path to image file(s)"
    )
    parser.add_argument(
        "--prompt", default="ì´ ì´ë¯¸ì§€ë“¤ì„ ë¶„ì„í•´ì„œ ìš”ì•½í•´ì¤˜", help="Analysis prompt"
    )
    parser.add_argument(
        "--max-tokens", type=int, default=512, help="Max tokens to generate"
    )
    parser.add_argument(
        "--model", default="mlx-community/Qwen3-VL-8B-Instruct-4bit", help="Model name"
    )

    args = parser.parse_args()

    # PoC ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    poc = Qwen3VLMLXPOC(args.model)

    # ëª¨ë¸ ì´ˆê¸°í™”
    print("ğŸ”§ Initializing models...")
    if not poc.initialize_models():
        print("âŒ Model initialization failed")
        return

    print("âœ… Models initialized successfully")

    # ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
    mem_info = poc.check_memory()
    print(f"Total memory: {mem_info['total_gb']:.1f} GB")
    print(f"Available memory: {mem_info['available_gb']:.1f} GB")
    # ì´ë¯¸ì§€ ë¶„ì„ ì‹¤í–‰
    print(f"\nğŸ–¼ï¸  Analyzing {len(args.images)} image(s)...")
    result = poc.run_visual_debugging_chain(args.images)

    if result and "error" not in result:
        print("\nğŸ¯ Visual Debugging Chain Result:")
        print("=" * 50)
        print("VISUAL ANALYSIS:")
        print(result["visual_analysis"])
        print("\n" + "=" * 50)
        print("CHAIN ANALYSIS:")
        print(result["chain_analysis"])
        print("=" * 50)

        # ìµœì¢… ë©”ëª¨ë¦¬ ìƒíƒœ
        final_mem = poc.check_memory()
        print(f"Final memory usage: {final_mem['used_gb']:.1f} GB")
    else:
        print(f"âŒ Chain execution failed: {result.get('error', 'Unknown error')}")


if __name__ == "__main__":
    main()
